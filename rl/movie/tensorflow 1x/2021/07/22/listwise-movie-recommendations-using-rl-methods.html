<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Movie List Recommender using Actor-critic based RL method | reconb</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Movie List Recommender using Actor-critic based RL method" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method" />
<meta property="og:description" content="Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method" />
<link rel="canonical" href="https://nb.recohut.com/rl/movie/tensorflow%201x/2021/07/22/listwise-movie-recommendations-using-rl-methods.html" />
<meta property="og:url" content="https://nb.recohut.com/rl/movie/tensorflow%201x/2021/07/22/listwise-movie-recommendations-using-rl-methods.html" />
<meta property="og:site_name" content="reconb" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-22T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://nb.recohut.com/rl/movie/tensorflow%201x/2021/07/22/listwise-movie-recommendations-using-rl-methods.html","@type":"BlogPosting","headline":"Movie List Recommender using Actor-critic based RL method","dateModified":"2021-07-22T00:00:00-05:00","datePublished":"2021-07-22T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://nb.recohut.com/rl/movie/tensorflow%201x/2021/07/22/listwise-movie-recommendations-using-rl-methods.html"},"description":"Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nb.recohut.com/feed.xml" title="reconb" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">reconb</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Movie List Recommender using Actor-critic based RL method</h1><p class="page-description">Training a list-wise movie recommender using actor-critic policy and evaluating offline using experience replay method</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-07-22T00:00:00-05:00" itemprop="datePublished">
        Jul 22, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      73 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#RL">RL</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Movie">Movie</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Tensorflow 1x">Tensorflow 1x</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/recohut-admin/reco-nb-stage/tree/master/_notebooks/2021-07-22-listwise-movie-recommendations-using-rl-methods.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/recohut-admin/reco-nb-stage/master?filepath=_notebooks%2F2021-07-22-listwise-movie-recommendations-using-rl-methods.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/recohut-admin/reco-nb-stage/blob/master/_notebooks/2021-07-22-listwise-movie-recommendations-using-rl-methods.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h3"><a href="#Setup">Setup </a></li>
<li class="toc-entry toc-h3"><a href="#Download-data">Download data </a></li>
<li class="toc-entry toc-h3"><a href="#DataGenerator-class">DataGenerator class </a></li>
<li class="toc-entry toc-h3"><a href="#EmbeddingsGenerator-class">EmbeddingsGenerator class </a></li>
<li class="toc-entry toc-h3"><a href="#Embeddings-helper-class">Embeddings helper class </a></li>
<li class="toc-entry toc-h3"><a href="#read_file-helper-function">read_file helper function </a></li>
<li class="toc-entry toc-h3"><a href="#read_embeddings-helper-function">read_embeddings helper function </a></li>
<li class="toc-entry toc-h3"><a href="#Environment-class">Environment class </a></li>
<li class="toc-entry toc-h3"><a href="#Actor-class">Actor class </a></li>
<li class="toc-entry toc-h3"><a href="#Critic-class">Critic class </a></li>
<li class="toc-entry toc-h3"><a href="#ReplayMemory-class">ReplayMemory class </a></li>
<li class="toc-entry toc-h3"><a href="#experience_replay-function">experience_replay function </a></li>
<li class="toc-entry toc-h3"><a href="#OrnsteinUhlenbeckNoise-class">OrnsteinUhlenbeckNoise class </a></li>
<li class="toc-entry toc-h3"><a href="#Hyperparameters">Hyperparameters </a></li>
<li class="toc-entry toc-h3"><a href="#Data-generation">Data generation </a></li>
<li class="toc-entry toc-h3"><a href="#Embedding-generation">Embedding generation </a></li>
<li class="toc-entry toc-h3"><a href="#Load-embeddings">Load embeddings </a></li>
<li class="toc-entry toc-h3"><a href="#Start-Agent-training">Start Agent training </a></li>
<li class="toc-entry toc-h2"><a href="#Testing">Testing </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Test-1---Trainset-and-target=False">Test 1 - Trainset and target=False </a></li>
<li class="toc-entry toc-h3"><a href="#Test-2---Trainset-and-target=True">Test 2 - Trainset and target=True </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-07-22-listwise-movie-recommendations-using-rl-methods.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Setup">
<a class="anchor" href="#Setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setup<a class="anchor-link" href="#Setup"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">tensorflow_version</span> <span class="mf">1.</span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow 1.x selected.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Download-data">
<a class="anchor" href="#Download-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Download data<a class="anchor-link" href="#Download-data"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Downloading Movielens dataset from official source</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">files</span><span class="o">.</span><span class="n">grouplens</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">movielens</span><span class="o">/</span><span class="n">ml</span><span class="o">-</span><span class="mi">100</span><span class="n">k</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">q</span> <span class="n">ml</span><span class="o">-</span><span class="mi">100</span><span class="n">k</span><span class="o">.</span><span class="n">zip</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="DataGenerator-class">
<a class="anchor" href="#DataGenerator-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataGenerator <code>class</code><a class="anchor-link" href="#DataGenerator-class"> </a>
</h3>
<ol>
<li>Load the data into pandas dataframe</li>
<li>List down user's rating history in chronological order</li>
<li>Generate a sample of state-action pair</li>
<li>Split the data into train/test</li>
<li>Store the data back into csv file format</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">():</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datapath</span><span class="p">,</span> <span class="n">itempath</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Load data from the DB MovieLens</span>
<span class="sd">    List the users and the items</span>
<span class="sd">    List all the users histories</span>
<span class="sd">    '''</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">datapath</span><span class="p">,</span> <span class="n">itempath</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">users</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>   <span class="c1">#list of all users</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>   <span class="c1">#list of all items</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">histo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_history</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test</span>  <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datapath</span><span class="p">,</span> <span class="n">itempath</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Load the data and merge the name of each movie. </span>
<span class="sd">    A row corresponds to a rate given by a user to a movie.</span>

<span class="sd">     Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    datapath :  string</span>
<span class="sd">                path to the data 100k MovieLens</span>
<span class="sd">                contains usersId;itemId;rating </span>
<span class="sd">    itempath :  string</span>
<span class="sd">                path to the data 100k MovieLens</span>
<span class="sd">                contains itemId;itemName</span>
<span class="sd">     Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result :    DataFrame</span>
<span class="sd">                Contains all the ratings </span>
<span class="sd">    '''</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">datapath</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> 
                       <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">,</span> <span class="s1">'itemId'</span><span class="p">,</span> <span class="s1">'rating'</span><span class="p">,</span> <span class="s1">'timestamp'</span><span class="p">])</span>
    <span class="n">movie_titles</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">itempath</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'|'</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">,</span> <span class="s1">'itemName'</span><span class="p">],</span>
                           <span class="n">usecols</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'latin-1'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">movie_titles</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="s1">'itemId'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">'left'</span><span class="p">)</span>


  <span class="k">def</span> <span class="nf">generate_history</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Group all rates given by users and store them from older to most recent.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result :    List(DataFrame)</span>
<span class="sd">                List of the historic for each user</span>
<span class="sd">    '''</span>
    <span class="n">historic_users</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">users</span><span class="p">):</span>
      <span class="n">temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">]</span> <span class="o">==</span> <span class="n">u</span><span class="p">]</span>
      <span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">'timestamp'</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
      <span class="n">temp</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'index'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">historic_users</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">historic_users</span>

  <span class="k">def</span> <span class="nf">sample_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_histo</span><span class="p">,</span> <span class="n">action_ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="n">max_state</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_action</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[]):</span>
    <span class="sd">'''</span>
<span class="sd">    For a given history, make one or multiple sampling.</span>
<span class="sd">    If no optional argument given for nb_states and nb_actions, then the sampling</span>
<span class="sd">    is random and each sample can have differents size for action and state.</span>
<span class="sd">    To normalize sampling we need to give list of the numbers of states and actions</span>
<span class="sd">    to be sampled.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    user_histo :  DataFrame</span>
<span class="sd">                      historic of user</span>
<span class="sd">    delimiter :       string, optional</span>
<span class="sd">                      delimiter for the csv</span>
<span class="sd">    action_ratio :    float, optional</span>
<span class="sd">                      ratio form which movies in history will be selected</span>
<span class="sd">    max_samp_by_user: int, optional</span>
<span class="sd">                      Nulber max of sample to make by user</span>
<span class="sd">    max_state :       int, optional</span>
<span class="sd">                      Number max of movies to take for the 'state' column</span>
<span class="sd">    max_action :      int, optional</span>
<span class="sd">                      Number max of movies to take for the 'action' action</span>
<span class="sd">    nb_states :       array(int), optional</span>
<span class="sd">                      Numbers of movies to be taken for each sample made on user's historic</span>
<span class="sd">    nb_actions :      array(int), optional</span>
<span class="sd">                      Numbers of rating to be taken for each sample made on user's historic</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    states :         List(String)</span>
<span class="sd">                     All the states sampled, format of a sample: itemId&amp;rating</span>
<span class="sd">    actions :        List(String)</span>
<span class="sd">                     All the actions sampled, format of a sample: itemId&amp;rating</span>
<span class="sd">  </span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    States must be before(timestamp&lt;) the actions.</span>
<span class="sd">    If given, size of nb_states is the numbller of sample by user</span>
<span class="sd">    sizes of nb_states and nb_actions must be equals</span>
<span class="sd">    '''</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">user_histo</span><span class="p">)</span>
    <span class="n">sep</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">action_ratio</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">nb_sample</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nb_states</span><span class="p">:</span>
      <span class="n">nb_states</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sep</span><span class="p">),</span> <span class="n">max_state</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_sample</span><span class="p">)]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nb_actions</span><span class="p">:</span>
      <span class="n">nb_actions</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">sep</span><span class="p">),</span> <span class="n">max_action</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_sample</span><span class="p">)]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">nb_states</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">),</span> <span class="s1">'Given array must have the same size'</span>
    
    <span class="n">states</span>  <span class="o">=</span> <span class="p">[]</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># SELECT SAMPLES IN HISTORY</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nb_states</span><span class="p">)):</span>
      <span class="n">sample_states</span> <span class="o">=</span> <span class="n">user_histo</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">sep</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nb_states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">sample_actions</span> <span class="o">=</span> <span class="n">user_histo</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">sep</span><span class="p">):]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      
      <span class="n">sample_state</span> <span class="o">=</span>  <span class="p">[]</span>
      <span class="n">sample_action</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_states</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
        <span class="n">row</span>   <span class="o">=</span> <span class="n">sample_states</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="c1"># FORMAT STATE</span>
        <span class="n">state</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">])</span> <span class="o">+</span> <span class="s1">'&amp;'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">'rating'</span><span class="p">])</span>
        <span class="n">sample_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
      
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_actions</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
        <span class="n">row</span>    <span class="o">=</span> <span class="n">sample_actions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="c1"># FORMAT ACTION</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">])</span> <span class="o">+</span> <span class="s1">'&amp;'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">'rating'</span><span class="p">])</span>
        <span class="n">sample_action</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

      <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_state</span><span class="p">)</span>
      <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_action</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span>

  <span class="k">def</span> <span class="nf">gen_train_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Shuffle the historic of users and separate it in a train and a test set.</span>
<span class="sd">    Store the ids for each set.</span>
<span class="sd">    An user can't be in both set.</span>

<span class="sd">     Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    test_ratio :  float</span>
<span class="sd">                  Ratio to control the sizes of the sets</span>
<span class="sd">    seed       :  float</span>
<span class="sd">                  Seed on the shuffle</span>
<span class="sd">    '''</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">random</span><span class="o">.</span><span class="n">Random</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">[:</span><span class="nb">int</span><span class="p">((</span><span class="n">test_ratio</span> <span class="o">*</span> <span class="n">n</span><span class="p">))]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">histo</span><span class="p">[</span><span class="nb">int</span><span class="p">((</span><span class="n">test_ratio</span> <span class="o">*</span> <span class="n">n</span><span class="p">)):]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_test</span>  <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">]</span>
    

  <span class="k">def</span> <span class="nf">write_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">histo_to_write</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">';'</span><span class="p">,</span> <span class="n">action_ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_state</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_action</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[]):</span>
    <span class="sd">'''</span>
<span class="sd">    From  a given historic, create a csv file with the format:</span>
<span class="sd">    columns : state;action_reward;n_state</span>
<span class="sd">    rows    : itemid&amp;rating1 | itemid&amp;rating2 | ... ; itemid&amp;rating3 | ... | itemid&amp;rating4; itemid&amp;rating1 | itemid&amp;rating2 | itemid&amp;rating3 | ... | item&amp;rating4</span>
<span class="sd">    at filename location.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename :        string</span>
<span class="sd">                      path to the file to be produced</span>
<span class="sd">    histo_to_write :  List(DataFrame)</span>
<span class="sd">                      List of the historic for each user</span>
<span class="sd">    delimiter :       string, optional</span>
<span class="sd">                      delimiter for the csv</span>
<span class="sd">    action_ratio :    float, optional</span>
<span class="sd">                      ratio form which movies in history will be selected</span>
<span class="sd">    max_samp_by_user: int, optional</span>
<span class="sd">                      Nulber max of sample to make by user</span>
<span class="sd">    max_state :       int, optional</span>
<span class="sd">                      Number max of movies to take for the 'state' column</span>
<span class="sd">    max_action :      int, optional</span>
<span class="sd">                      Number max of movies to take for the 'action' action</span>
<span class="sd">    nb_states :       array(int), optional</span>
<span class="sd">                      Numbers of movies to be taken for each sample made on user's historic</span>
<span class="sd">    nb_actions :      array(int), optional</span>
<span class="sd">                      Numbers of rating to be taken for each sample made on user's historic</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    if given, size of nb_states is the numbller of sample by user</span>
<span class="sd">    sizes of nb_states and nb_actions must be equals</span>

<span class="sd">    '''</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
      <span class="n">f_writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="n">delimiter</span><span class="p">)</span>
      <span class="n">f_writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="s1">'state'</span><span class="p">,</span> <span class="s1">'action_reward'</span><span class="p">,</span> <span class="s1">'n_state'</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">user_histo</span> <span class="ow">in</span> <span class="n">histo_to_write</span><span class="p">:</span>
        <span class="n">states</span><span class="p">,</span> <span class="n">actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_history</span><span class="p">(</span><span class="n">user_histo</span><span class="p">,</span> <span class="n">action_ratio</span><span class="p">,</span> <span class="n">max_samp_by_user</span><span class="p">,</span> <span class="n">max_state</span><span class="p">,</span> <span class="n">max_action</span><span class="p">,</span> <span class="n">nb_states</span><span class="p">,</span> <span class="n">nb_actions</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)):</span>
          <span class="c1"># FORMAT STATE</span>
          <span class="n">state_str</span>   <span class="o">=</span> <span class="s1">'|'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="c1"># FORMAT ACTION</span>
          <span class="n">action_str</span>  <span class="o">=</span> <span class="s1">'|'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="c1"># FORMAT N_STATE</span>
          <span class="n">n_state_str</span> <span class="o">=</span> <span class="n">state_str</span> <span class="o">+</span> <span class="s1">'|'</span> <span class="o">+</span> <span class="n">action_str</span>
          <span class="n">f_writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="n">state_str</span><span class="p">,</span> <span class="n">action_str</span><span class="p">,</span> <span class="n">n_state_str</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="EmbeddingsGenerator-class">
<a class="anchor" href="#EmbeddingsGenerator-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>EmbeddingsGenerator <code>class</code><a class="anchor-link" href="#EmbeddingsGenerator-class"> </a>
</h3>
<ol>
<li>Load the data</li>
<li>Build a keras sequential model</li>
<li>Convert train and test set into required format</li>
<li>Train and evaluate the model</li>
<li>Generate item embeddings for each movie id</li>
<li>Save the embeddings into a csv file</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">EmbeddingsGenerator</span><span class="p">:</span>
  <span class="k">def</span>  <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_users</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_users</span> <span class="o">=</span> <span class="n">train_users</span>

    <span class="c1">#preprocess</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">'timestamp'</span><span class="p">])</span>
    <span class="c1">#make them start at 0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'itemId'</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1">#list of rated movies by each user</span>
    <span class="k">for</span> <span class="n">userId</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_count</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">userId</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">userId</span> <span class="o">==</span> <span class="n">userId</span><span class="p">][</span><span class="s1">'itemId'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">)))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="n">m</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">m</span>
  
  <span class="k">def</span> <span class="nf">generate_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Returns a context and a target for the user_id</span>
<span class="sd">    context: user's history with one random movie removed</span>
<span class="sd">    target: id of random removed movie</span>
<span class="sd">    '''</span>
    <span class="n">user_movies_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">])</span>
    <span class="c1">#picking random movie</span>
    <span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">user_movies_count</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># -1 avoids taking the last movie</span>
    <span class="c1">#setting target</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">))</span>
    <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">][</span><span class="n">random_index</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1">#setting context</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">))</span>
    <span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">][:</span><span class="n">random_index</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_movies</span><span class="p">[</span><span class="n">user_id</span><span class="p">][</span><span class="n">random_index</span><span class="o">+</span><span class="mi">1</span><span class="p">:]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">target</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_epochs</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Trains the model from train_users's history</span>
<span class="sd">    '''</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_epochs</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_epochs</span><span class="p">))</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_input</span><span class="p">(</span><span class="n">user_id</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_users</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
      <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
      <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_users</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Returns [loss, accuracy] on the test set</span>
<span class="sd">    '''</span>
    <span class="n">batch_test</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_input</span><span class="p">(</span><span class="n">user_id</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">test_users</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_test</span><span class="p">])</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_test</span><span class="p">])</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">save_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Generates a csv file containg the vector embedding for each movie.</span>
<span class="sd">    '''</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">input</span>                                           <span class="c1"># input placeholder</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">layers</span><span class="p">]</span>          <span class="c1"># all layer outputs</span>
    <span class="n">functor</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="n">inp</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">learning_phase</span><span class="p">()],</span> <span class="n">outputs</span> <span class="p">)</span>   <span class="c1"># evaluation function</span>

    <span class="c1">#append embeddings to vectors</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">movie_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">):</span>
      <span class="n">movie</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">movie_count</span><span class="p">))</span>
      <span class="n">movie</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">movie_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">layer_outs</span> <span class="o">=</span> <span class="n">functor</span><span class="p">([</span><span class="n">movie</span><span class="p">])</span>
      <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">layer_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
      <span class="n">vector</span> <span class="o">=</span> <span class="s1">'|'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
      <span class="n">vectors</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">movie_id</span><span class="p">,</span> <span class="n">vector</span><span class="p">])</span>

    <span class="c1">#saves as a csv file</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'item_id'</span><span class="p">,</span> <span class="s1">'vectors'</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">'item_id'</span><span class="p">:</span> <span class="s1">'int32'</span><span class="p">})</span>
    <span class="n">embeddings</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">';'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Embeddings-helper-class">
<a class="anchor" href="#Embeddings-helper-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>Embeddings <code>helper class</code><a class="anchor-link" href="#Embeddings-helper-class"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Embeddings</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">item_embeddings</span>
  
  <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  
  <span class="k">def</span> <span class="nf">get_embedding_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span>
  
  <span class="k">def</span> <span class="nf">get_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_index</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">[</span><span class="n">item_index</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_list</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="read_file-helper-function">
<a class="anchor" href="#read_file-helper-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>read_file <code>helper function</code><a class="anchor-link" href="#read_file-helper-function"> </a>
</h3>
<p>This function will read the stored data csv files into pandas dataframe</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">read_file</span><span class="p">(</span><span class="n">data_path</span><span class="p">):</span>
  <span class="sd">''' Load data from train.csv or test.csv. '''</span>

  <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">';'</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'state'</span><span class="p">,</span> <span class="s1">'n_state'</span><span class="p">,</span> <span class="s1">'action_reward'</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ee</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'&amp;'</span><span class="p">)]</span> <span class="k">for</span> <span class="n">ee</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'|'</span><span class="p">)])</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]]</span>
  <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'state'</span><span class="p">,</span> <span class="s1">'n_state'</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">l</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]]</span>

  <span class="n">data</span><span class="p">[</span><span class="s1">'action'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'action_reward'</span><span class="p">]]</span>
  <span class="n">data</span><span class="p">[</span><span class="s1">'reward'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'action_reward'</span><span class="p">]]</span>
  <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'action_reward'</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="read_embeddings-helper-function">
<a class="anchor" href="#read_embeddings-helper-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>read_embeddings <code>helper function</code><a class="anchor-link" href="#read_embeddings-helper-function"> </a>
</h3>
<p>This function will read the stored embedding csv file into pandas dataframe and return as multi-dimensional array</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">read_embeddings</span><span class="p">(</span><span class="n">embeddings_path</span><span class="p">):</span>
  <span class="sd">''' Load embeddings (a vector for each item). '''</span>
  
  <span class="n">embeddings</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">embeddings_path</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">';'</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'|'</span><span class="p">)]</span>
                   <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">embeddings</span><span class="p">[</span><span class="s1">'vectors'</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Environment-class">
<a class="anchor" href="#Environment-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>Environment <code>class</code><a class="anchor-link" href="#Environment-class"> </a>
</h3>
<p>This is the simulator. It will help orchestrating the whole process of learning list recommendations by our actor-critic based MDP agent.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Environment</span><span class="p">():</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">fixed_length</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">'state'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">item_id</span><span class="p">)</span> 
      <span class="k">for</span> <span class="n">item_id</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">'state'</span><span class="p">]])</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">'action'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">item_id</span><span class="p">)</span> 
      <span class="k">for</span> <span class="n">item_id</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">'action'</span><span class="p">]])</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">'reward'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'reward'</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span> <span class="c1"># Î± (alpha) in Equation (1)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span> <span class="c1"># Î“ (Gamma) in Equation (4)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fixed_length</span> <span class="o">=</span> <span class="n">fixed_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_groups</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="p">[</span><span class="s1">'state'</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_state</span>

  <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Compute reward and update state.</span>
<span class="sd">    Args:</span>
<span class="sd">      actions: embedded chosen items.</span>
<span class="sd">    Returns:</span>
<span class="sd">      cumulated_reward: overall reward.</span>
<span class="sd">      current_state: updated state.</span>
<span class="sd">    '''</span>

    <span class="c1"># '18: Compute overall reward r_t according to Equation (4)'</span>
    <span class="n">simulated_rewards</span><span class="p">,</span> <span class="n">cumulated_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulate_rewards</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_state</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">actions</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

    <span class="c1"># '11: Set s_t+1 = s_t' &lt;=&gt; self.current_state = self.current_state</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">simulated_rewards</span><span class="p">)):</span> <span class="c1"># '12: for k = 1, K do'</span>
      <span class="k">if</span> <span class="n">simulated_rewards</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># '13: if r_t^k &gt; 0 then'</span>
        <span class="c1"># '14: Add a_t^k to the end of s_t+1'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span> <span class="p">[</span><span class="n">actions</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_length</span><span class="p">:</span> <span class="c1"># '15: Remove the first item of s_t+1'</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cumulated_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_state</span>

  <span class="k">def</span> <span class="nf">get_groups</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">''' Calculate average state/action value for each group. Equation (3). '''</span>

    <span class="n">groups</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">'reward'</span><span class="p">]):</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">'state'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
      <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">'action'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
      <span class="n">groups</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">'size'</span><span class="p">:</span> <span class="n">size</span><span class="p">,</span> <span class="c1"># N_x in article</span>
        <span class="s1">'rewards'</span><span class="p">:</span> <span class="n">rewards</span><span class="p">,</span> <span class="c1"># U_x in article (combination of rewards)</span>
        <span class="s1">'average state'</span><span class="p">:</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">states</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="c1"># s_x^-</span>
        <span class="s1">'average action'</span><span class="p">:</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">actions</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># a_x^-</span>
      <span class="p">})</span>
    <span class="k">return</span> <span class="n">groups</span>

  <span class="k">def</span> <span class="nf">simulate_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_state</span><span class="p">,</span> <span class="n">chosen_actions</span><span class="p">,</span> <span class="n">reward_type</span><span class="o">=</span><span class="s1">'grouped cosine'</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Calculate simulated rewards.</span>
<span class="sd">    Args:</span>
<span class="sd">      current_state: history, list of embedded items.</span>
<span class="sd">      chosen_actions: embedded chosen items.</span>
<span class="sd">      reward_type: from ['normal', 'grouped average', 'grouped cosine'].</span>
<span class="sd">    Returns:</span>
<span class="sd">      returned_rewards: most probable rewards.</span>
<span class="sd">      cumulated_reward: probability weighted rewards.</span>
<span class="sd">    '''</span>

    <span class="c1"># Equation (1)</span>
    <span class="k">def</span> <span class="nf">cosine_state_action</span><span class="p">(</span><span class="n">s_t</span><span class="p">,</span> <span class="n">a_t</span><span class="p">,</span> <span class="n">s_i</span><span class="p">,</span> <span class="n">a_i</span><span class="p">):</span>
      <span class="n">cosine_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s_t</span><span class="p">,</span> <span class="n">s_i</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">s_t</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">s_i</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="n">cosine_action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="n">a_i</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a_i</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">cosine_state</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">cosine_action</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>

    <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">'normal'</span><span class="p">:</span>
      <span class="c1"># Calculate simulated reward in normal way: Equation (2)</span>
      <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[</span><span class="n">cosine_state_action</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">chosen_actions</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s1">'state'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">'action'</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">'grouped average'</span><span class="p">:</span>
      <span class="c1"># Calculate simulated reward by grouped average: Equation (3)</span>
      <span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">g</span><span class="p">[</span><span class="s1">'size'</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">])</span> <span class="o">*</span>\
        <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="s1">'average state'</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>\
        <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">chosen_actions</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="s1">'average action'</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">chosen_actions</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">'grouped cosine'</span><span class="p">:</span>
      <span class="c1"># Calculate simulated reward by grouped cosine: Equations (1) and (3)</span>
      <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[</span><span class="n">cosine_state_action</span><span class="p">(</span><span class="n">current_state</span><span class="p">,</span> <span class="n">chosen_actions</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="s1">'average state'</span><span class="p">],</span> <span class="n">g</span><span class="p">[</span><span class="s1">'average action'</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">]</span>

    <span class="c1"># Normalize (sum to 1)</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>

    <span class="c1"># Get most probable rewards</span>
    <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">'normal'</span><span class="p">:</span>
      <span class="n">returned_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedded_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)][</span><span class="s1">'reward'</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'grouped average'</span><span class="p">,</span> <span class="s1">'grouped cosine'</span><span class="p">]:</span>
      <span class="n">returned_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)][</span><span class="s1">'rewards'</span><span class="p">]</span>

    <span class="c1"># Equation (4)</span>
    <span class="k">def</span> <span class="nf">overall_reward</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">gamma</span><span class="o">**</span><span class="n">k</span> <span class="o">*</span> <span class="n">reward</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">reward</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rewards</span><span class="p">)])</span>

    <span class="k">if</span> <span class="n">reward_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'normal'</span><span class="p">,</span> <span class="s1">'grouped average'</span><span class="p">]:</span>
      <span class="c1"># Get cumulated reward: Equation (4)</span>
      <span class="n">cumulated_reward</span> <span class="o">=</span> <span class="n">overall_reward</span><span class="p">(</span><span class="n">returned_rewards</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">'grouped cosine'</span><span class="p">:</span>
      <span class="c1"># Get probability weighted cumulated reward</span>
      <span class="n">cumulated_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">p</span> <span class="o">*</span> <span class="n">overall_reward</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="s1">'rewards'</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)])</span>

    <span class="k">return</span> <span class="n">returned_rewards</span><span class="p">,</span> <span class="n">cumulated_reward</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Actor-class">
<a class="anchor" href="#Actor-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>Actor <code>class</code><a class="anchor-link" href="#Actor-class"> </a>
</h3>
<p>This is the policy approximator actor</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Actor</span><span class="p">():</span>
  <span class="sd">''' Policy function approximator. '''</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">'actor'</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">sess</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span> <span class="o">=</span> <span class="n">state_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">action_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ra_length</span> <span class="o">=</span> <span class="n">ra_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span> <span class="o">=</span> <span class="n">history_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope</span> <span class="o">=</span> <span class="n">scope</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Build Actor network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">action_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">'estimator_actor'</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>

      <span class="c1"># Build target Actor network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_action_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">'target_actor'</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">):]</span> <span class="c1"># TODO: why sublist [len(x):]? Maybe because its equal to network_params + target_network_params</span>

      <span class="c1"># Initialize target network weights with network weights (Î¸^Ï€â€² â† Î¸^Ï€)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>
        
      <span class="c1"># Update target network weights (Î¸^Ï€â€² â† Ï„Î¸^Ï€ + (1 âˆ’ Ï„)Î¸^Ï€â€²)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>

      <span class="c1"># Gradient computation from Critic's action_gradients</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">])</span>
      <span class="n">gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_weights</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'42222222222'</span><span class="p">),</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span><span class="p">)</span>
      <span class="n">params_gradients</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">),</span> <span class="n">gradients</span><span class="p">))</span>
      
      <span class="c1"># Compute âˆ‡_a.Q(s, a|Î¸^Âµ).âˆ‡_Î¸^Ï€.f_Î¸^Ï€(s)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
          <span class="nb">zip</span><span class="p">(</span><span class="n">params_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_build_net</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">):</span>
    <span class="sd">''' Build the (target) Actor network. '''</span>

    <span class="k">def</span> <span class="nf">gather_last_output</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
      <span class="k">def</span> <span class="nf">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

      <span class="n">batch_range</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">tmp_end</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">seq_lens</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">tmp_end</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Inputs: current state, sequence_length</span>
      <span class="c1"># Outputs: action weights to compute the score Equation (6)</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">],</span> <span class="s1">'state'</span><span class="p">)</span>
      <span class="n">state_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>
      <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="s1">'sequence_length'</span><span class="p">)</span>
      <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span>
                                    <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                                    <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(),</span>
                                    <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">state_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">)</span>
      <span class="n">last_output</span> <span class="o">=</span> <span class="n">gather_last_output</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span> <span class="c1"># TODO: replace by h</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ra_length</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">)(</span><span class="n">last_output</span><span class="p">)</span>
      <span class="n">action_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ra_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">action_weights</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">action_gradients</span><span class="p">):</span>
    <span class="sd">'''  Compute âˆ‡_a.Q(s, a|Î¸^Âµ).âˆ‡_Î¸^Ï€.f_Î¸^Ï€(s). '''</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span><span class="p">:</span> <span class="n">action_gradients</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_weights</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_action_weights</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">init_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">update_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">get_recommendation_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">noisy_state</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Algorithm 2</span>
<span class="sd">    Args:</span>
<span class="sd">      ra_length: length of the recommendation list.</span>
<span class="sd">      noisy_state: current/remembered environment state with noise.</span>
<span class="sd">      embeddings: Embeddings object.</span>
<span class="sd">      target: boolean to use Actor's network or target network.</span>
<span class="sd">    Returns:</span>
<span class="sd">      Recommendation List: list of embedded items as future actions.</span>
<span class="sd">    '''</span>

    <span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
      <span class="sd">'''</span>
<span class="sd">      Equation (6)</span>
<span class="sd">      Args:</span>
<span class="sd">        weights: w_t^k shape=(embedding_size,).</span>
<span class="sd">        embedding: e_i shape=(embedding_size,).</span>
<span class="sd">      Returns:</span>
<span class="sd">        score of the item i: score_i=w_t^k.e_i^T shape=(1,).</span>
<span class="sd">      '''</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">embedding</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">ret</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">noisy_state</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># '1: Generate w_t = {w_t^1, ..., w_t^K} according to Equation (5)'</span>
    <span class="n">method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_target</span> <span class="k">if</span> <span class="n">target</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">method</span><span class="p">(</span><span class="n">noisy_state</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="c1"># '3: Score items in I according to Equation (6)'</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="n">get_score</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">],</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding_vector</span><span class="p">()]</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ra_length</span><span class="p">)]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>

    <span class="c1"># '8: return a_t'</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]))</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ra_length</span><span class="p">)]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Critic-class">
<a class="anchor" href="#Critic-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>Critic <code>class</code><a class="anchor-link" href="#Critic-class"> </a>
</h3>
<p>This is the value approximator critic</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Critic</span><span class="p">():</span>
  <span class="sd">''' Value function approximator. '''</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">'critic'</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">sess</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span> <span class="o">=</span> <span class="n">state_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">action_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span> <span class="o">=</span> <span class="n">history_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope</span> <span class="o">=</span> <span class="n">scope</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Build Critic network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">'estimator_critic'</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">TRAINABLE_VARIABLES</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">'estimator_critic'</span><span class="p">)</span>

      <span class="c1"># Build target Critic network</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_net</span><span class="p">(</span><span class="s1">'target_critic'</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">TRAINABLE_VARIABLES</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">'target_critic'</span><span class="p">)</span>

      <span class="c1"># Initialize target network weights with network weights (Î¸^Âµâ€² â† Î¸^Âµ)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>

      <span class="c1"># Update target network weights (Î¸^Âµâ€² â† Ï„Î¸^Âµ + (1 âˆ’ Ï„)Î¸^Âµâ€²)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_network_params</span><span class="p">))]</span>

      <span class="c1"># Minimize MSE between Critic's and target Critic's outputed Q-values</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">expected_reward</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">expected_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

      <span class="c1"># Compute âˆ‡_a.Q(s, a|Î¸^Âµ)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_build_net</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scope</span><span class="p">):</span>
    <span class="sd">''' Build the (target) Critic network. '''</span>

    <span class="k">def</span> <span class="nf">gather_last_output</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">):</span>
      <span class="k">def</span> <span class="nf">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

      <span class="n">this_range</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">seq_lens</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">tmp_end</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">cli_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">seq_lens</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">this_range</span><span class="p">,</span> <span class="n">tmp_end</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
      <span class="c1"># Inputs: current state, current action</span>
      <span class="c1"># Outputs: predicted Q-value</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">],</span> <span class="s1">'state'</span><span class="p">)</span>
      <span class="n">state_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">history_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>
      <span class="n">action</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">],</span> <span class="s1">'action'</span><span class="p">)</span>
      <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'critic_sequence_length'</span><span class="p">)</span>
      <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history_length</span><span class="p">,</span>
                                    <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                                    <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(),</span>
                                    <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
      <span class="n">predicted_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">state_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">)</span>
      <span class="n">predicted_state</span> <span class="o">=</span> <span class="n">gather_last_output</span><span class="p">(</span><span class="n">predicted_state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>

      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">predicted_state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">layer1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">layer2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">layer1</span><span class="p">)</span>
      <span class="n">critic_Q_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">layer2</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">critic_Q_value</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">expected_reward</span><span class="p">):</span>
    <span class="sd">''' Minimize MSE between expected reward and target Critic's Q-value. '''</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">],</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">expected_reward</span><span class="p">:</span> <span class="n">expected_reward</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="sd">''' Returns Critic's predicted Q-value. '''</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_Q_value</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">predict_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="sd">''' Returns target Critic's predicted Q-value. '''</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_Q_value</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})</span>

  <span class="k">def</span> <span class="nf">get_action_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
    <span class="sd">''' Returns âˆ‡_a.Q(s, a|Î¸^Âµ). '''</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_gradients</span><span class="p">,</span>
                         <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">:</span> <span class="n">sequence_length</span><span class="p">})[</span><span class="mi">0</span><span class="p">])</span>

  <span class="k">def</span> <span class="nf">init_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_target_network_params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">update_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update_target_network_params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReplayMemory-class">
<a class="anchor" href="#ReplayMemory-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>ReplayMemory <code>class</code><a class="anchor-link" href="#ReplayMemory-class"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">ReplayMemory</span><span class="p">():</span>
  <span class="sd">''' Replay memory D. '''</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
    <span class="c1"># self.buffer = [[row['state'], row['action'], row['reward'], row['n_state']] for _, row in data.iterrows()][-self.buffer_size:] TODO: empty or not?</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">n_state</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">n_state</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">sample_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="experience_replay-function">
<a class="anchor" href="#experience_replay-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>experience_replay <code>function</code><a class="anchor-link" href="#experience_replay-function"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">experience_replay</span><span class="p">(</span><span class="n">replay_memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">discount_factor</span><span class="p">):</span>
  <span class="sd">'''</span>
<span class="sd">  Experience replay.</span>
<span class="sd">  Args:</span>
<span class="sd">    replay_memory: replay memory D in article.</span>
<span class="sd">    batch_size: sample size.</span>
<span class="sd">    actor: Actor network.</span>
<span class="sd">    critic: Critic network.</span>
<span class="sd">    embeddings: Embeddings object.</span>
<span class="sd">    state_space_size: dimension of states.</span>
<span class="sd">    action_space_size: dimensions of actions.</span>
<span class="sd">  Returns:</span>
<span class="sd">    Best Q-value, loss of Critic network for printing/recording purpose.</span>
<span class="sd">  '''</span>

  <span class="c1"># '22: Sample minibatch of N transitions (s, a, r, sâ€²) from D'</span>
  <span class="n">samples</span> <span class="o">=</span> <span class="n">replay_memory</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
  <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
  <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
  <span class="n">n_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">)</span>

  <span class="c1"># '23: Generate aâ€² by target Actor network according to Algorithm 2'</span>
  <span class="n">n_actions</span> <span class="o">=</span> <span class="n">actor</span><span class="o">.</span><span class="n">get_recommendation_list</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">)</span>

  <span class="c1"># Calculate predicted Qâ€²(sâ€², aâ€²|Î¸^Âµâ€²) value</span>
  <span class="n">target_Q_value</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">predict_target</span><span class="p">(</span><span class="n">n_states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>

  <span class="c1"># '24: Set y = r + Î³Qâ€²(sâ€², aâ€²|Î¸^Âµâ€²)'</span>
  <span class="n">expected_rewards</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">target_Q_value</span>
  
  <span class="c1"># '25: Update Critic by minimizing (y âˆ’ Q(s, a|Î¸^Âµ))Â²'</span>
  <span class="n">critic_Q_value</span><span class="p">,</span> <span class="n">critic_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">expected_rewards</span><span class="p">)</span>
  
  <span class="c1"># '26: Update the Actor using the sampled policy gradient'</span>
  <span class="n">action_gradients</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">get_action_gradients</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
  <span class="n">actor</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="p">[</span><span class="n">ra_length</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">action_gradients</span><span class="p">)</span>

  <span class="c1"># '27: Update the Critic target networks'</span>
  <span class="n">critic</span><span class="o">.</span><span class="n">update_target_network</span><span class="p">()</span>

  <span class="c1"># '28: Update the Actor target network'</span>
  <span class="n">actor</span><span class="o">.</span><span class="n">update_target_network</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">critic_Q_value</span><span class="p">),</span> <span class="n">critic_loss</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OrnsteinUhlenbeckNoise-class">
<a class="anchor" href="#OrnsteinUhlenbeckNoise-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>OrnsteinUhlenbeckNoise <code>class</code><a class="anchor-link" href="#OrnsteinUhlenbeckNoise-class"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">OrnsteinUhlenbeckNoise</span><span class="p">:</span>
  <span class="sd">''' Noise for Actor predictions. '''</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">action_space_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span>

  <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">environment</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">discount_factor</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="p">,</span> <span class="n">filename_summary</span><span class="p">):</span>
  <span class="sd">''' Algorithm 3 in article. '''</span>

  <span class="c1"># Set up summary operators</span>
  <span class="k">def</span> <span class="nf">build_summaries</span><span class="p">():</span>
    <span class="n">episode_reward</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">'reward'</span><span class="p">,</span> <span class="n">episode_reward</span><span class="p">)</span>
    <span class="n">episode_max_Q</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">'max_Q_value'</span><span class="p">,</span> <span class="n">episode_max_Q</span><span class="p">)</span>
    <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">'critic_loss'</span><span class="p">,</span> <span class="n">critic_loss</span><span class="p">)</span>

    <span class="n">summary_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">episode_reward</span><span class="p">,</span> <span class="n">episode_max_Q</span><span class="p">,</span> <span class="n">critic_loss</span><span class="p">]</span>
    <span class="n">summary_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">summary_ops</span><span class="p">,</span> <span class="n">summary_vars</span>

  <span class="n">summary_ops</span><span class="p">,</span> <span class="n">summary_vars</span> <span class="o">=</span> <span class="n">build_summaries</span><span class="p">()</span>
  <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
  <span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">filename_summary</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

  <span class="c1"># '2: Initialize target network fâ€² and Qâ€²'</span>
  <span class="n">actor</span><span class="o">.</span><span class="n">init_target_network</span><span class="p">()</span>
  <span class="n">critic</span><span class="o">.</span><span class="n">init_target_network</span><span class="p">()</span>

  <span class="c1"># '3: Initialize the capacity of replay memory D'</span>
  <span class="n">replay_memory</span> <span class="o">=</span> <span class="n">ReplayMemory</span><span class="p">(</span><span class="n">buffer_size</span><span class="p">)</span> <span class="c1"># Memory D in article</span>
  <span class="n">replay</span> <span class="o">=</span> <span class="kc">False</span>


  <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i_session</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_episodes</span><span class="p">):</span> <span class="c1"># '4: for session = 1, M do'</span>
    <span class="n">session_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">session_Q_value</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">session_critic_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># '5: Reset the item space I' is useless because unchanged.</span>

    <span class="n">states</span> <span class="o">=</span> <span class="n">environment</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># '6: Initialize state s_0 from previous sessions'</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">i_session</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Update average parameters every 10 episodes</span>
      <span class="n">environment</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">environment</span><span class="o">.</span><span class="n">get_groups</span><span class="p">()</span>
      
    <span class="n">exploration_noise</span> <span class="o">=</span> <span class="n">OrnsteinUhlenbeckNoise</span><span class="p">(</span><span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_rounds</span><span class="p">):</span> <span class="c1"># '7: for t = 1, T do'</span>
      <span class="c1"># '8: Stage 1: Transition Generating Stage'</span>

      <span class="c1"># '9: Select an action a_t = {a_t^1, ..., a_t^K} according to Algorithm 2'</span>
      <span class="n">actions</span> <span class="o">=</span> <span class="n">actor</span><span class="o">.</span><span class="n">get_recommendation_list</span><span class="p">(</span>
          <span class="n">ra_length</span><span class="p">,</span>
          <span class="n">states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># TODO + exploration_noise.get().reshape(1, -1),</span>
          <span class="n">embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

      <span class="c1"># '10: Execute action a_t and observe the reward list {r_t^1, ..., r_t^K} for each item in a_t'</span>
      <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="n">environment</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>

      <span class="c1"># '19: Store transition (s_t, a_t, r_t, s_t+1) in D'</span>
      <span class="n">replay_memory</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                        <span class="n">actions</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ra_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                        <span class="p">[</span><span class="n">rewards</span><span class="p">],</span>
                        <span class="n">next_states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>

      <span class="n">states</span> <span class="o">=</span> <span class="n">next_states</span> <span class="c1"># '20: Set s_t = s_t+1'</span>

      <span class="n">session_reward</span> <span class="o">+=</span> <span class="n">rewards</span>
      
      <span class="c1"># '21: Stage 2: Parameter Updating Stage'</span>
      <span class="k">if</span> <span class="n">replay_memory</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">batch_size</span><span class="p">:</span> <span class="c1"># Experience replay</span>
        <span class="n">replay</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">replay_Q_value</span><span class="p">,</span> <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">experience_replay</span><span class="p">(</span><span class="n">replay_memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
          <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
          <span class="n">ra_length</span> <span class="o">*</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">discount_factor</span><span class="p">)</span>
        <span class="n">session_Q_value</span> <span class="o">+=</span> <span class="n">replay_Q_value</span>
        <span class="n">session_critic_loss</span> <span class="o">+=</span> <span class="n">critic_loss</span>

      <span class="n">summary_str</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">summary_ops</span><span class="p">,</span>
                             <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">summary_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">session_reward</span><span class="p">,</span>
                                        <span class="n">summary_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">session_Q_value</span><span class="p">,</span>
                                        <span class="n">summary_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">session_critic_loss</span><span class="p">})</span>
      
      <span class="n">writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary_str</span><span class="p">,</span> <span class="n">i_session</span><span class="p">)</span>

      <span class="sd">'''</span>
<span class="sd">      print(state_to_items(embeddings.embed(data['state'][0]), actor, ra_length, embeddings),</span>
<span class="sd">            state_to_items(embeddings.embed(data['state'][0]), actor, ra_length, embeddings, True))</span>
<span class="sd">      '''</span>

    <span class="n">str_loss</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">'Loss=</span><span class="si">%0.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="n">session_critic_loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">'Episode </span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1"> Reward=</span><span class="si">%d</span><span class="s1"> Time=</span><span class="si">%d</span><span class="s1">s '</span> <span class="o">+</span> <span class="p">(</span><span class="n">str_loss</span> <span class="k">if</span> <span class="n">replay</span> <span class="k">else</span> <span class="s1">'No replay'</span><span class="p">))</span> <span class="o">%</span> <span class="p">(</span><span class="n">i_session</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="p">,</span> <span class="n">session_reward</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

  <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">'models.h5'</span><span class="p">,</span> <span class="n">write_meta_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameters">
<a class="anchor" href="#Hyperparameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameters<a class="anchor-link" href="#Hyperparameters"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">history_length</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># N in article</span>
<span class="n">ra_length</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># K in article</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.99</span> <span class="c1"># Gamma in Bellman equation</span>
<span class="n">actor_lr</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">critic_lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># Ï„ in Algorithm 3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">nb_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">nb_rounds</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">filename_summary</span> <span class="o">=</span> <span class="s1">'summary.txt'</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># Î± (alpha) in Equation (1)</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># Î“ (Gamma) in Equation (4)</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">1000000</span> <span class="c1"># Size of replay memory D in article</span>
<span class="n">fixed_length</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Fixed memory length</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-generation">
<a class="anchor" href="#Data-generation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data generation<a class="anchor-link" href="#Data-generation"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">dg</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="s1">'ml-100k/u.data'</span><span class="p">,</span> <span class="s1">'ml-100k/u.item'</span><span class="p">)</span>
<span class="n">dg</span><span class="o">.</span><span class="n">gen_train_test</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">dg</span><span class="o">.</span><span class="n">write_csv</span><span class="p">(</span><span class="s1">'train.csv'</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[</span><span class="n">history_length</span><span class="p">],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[</span><span class="n">ra_length</span><span class="p">])</span>
<span class="n">dg</span><span class="o">.</span><span class="n">write_csv</span><span class="p">(</span><span class="s1">'test.csv'</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">nb_states</span><span class="o">=</span><span class="p">[</span><span class="n">history_length</span><span class="p">],</span> <span class="n">nb_actions</span><span class="o">=</span><span class="p">[</span><span class="n">ra_length</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">read_file</span><span class="p">(</span><span class="s1">'train.csv'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>n_state</th>
      <th>action</th>
      <th>reward</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[732, 257, 507, 602, 481, 568, 1286, 50, 501, ...</td>
      <td>[732, 257, 507, 602, 481, 568, 1286, 50, 501, ...</td>
      <td>[731, 525, 80, 88]</td>
      <td>(3, 4, 3, 3)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[1226, 855, 339, 124, 16, 147, 59, 827, 323, 2...</td>
      <td>[1226, 855, 339, 124, 16, 147, 59, 827, 323, 2...</td>
      <td>[52, 1005, 347, 70]</td>
      <td>(4, 5, 4, 3)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[316, 286, 313, 748, 258, 272, 300, 302, 347, ...</td>
      <td>[316, 286, 313, 748, 258, 272, 300, 302, 347, ...</td>
      <td>[751, 271, 689, 289]</td>
      <td>(4, 4, 4, 5)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[235, 433, 96, 117, 429, 7, 471, 201, 276, 55,...</td>
      <td>[235, 433, 96, 117, 429, 7, 471, 201, 276, 55,...</td>
      <td>[31, 198, 724, 654]</td>
      <td>(3, 5, 3, 4)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[77, 241, 98, 423, 71, 157, 955, 186, 121, 421...</td>
      <td>[77, 241, 98, 423, 71, 157, 955, 186, 121, 421...</td>
      <td>[316, 427, 313, 959]</td>
      <td>(4, 5, 4, 5)</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Embedding-generation">
<a class="anchor" href="#Embedding-generation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Embedding generation<a class="anchor-link" href="#Embedding-generation"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">if</span> <span class="kc">True</span><span class="p">:</span> <span class="c1"># Generate embeddings?</span>
  <span class="n">eg</span> <span class="o">=</span> <span class="n">EmbeddingsGenerator</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">user_train</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'ml-100k/u.data'</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'userId'</span><span class="p">,</span> <span class="s1">'itemId'</span><span class="p">,</span> <span class="s1">'rating'</span><span class="p">,</span> <span class="s1">'timestamp'</span><span class="p">]))</span>
  <span class="n">eg</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">nb_epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
  <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">eg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">user_train</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Train set: Loss=</span><span class="si">%.4f</span><span class="s1"> ; Accuracy=</span><span class="si">%.1f%%</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
  <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">eg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">user_test</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Test set: Loss=</span><span class="si">%.4f</span><span class="s1"> ; Accuracy=</span><span class="si">%.1f%%</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
  <span class="n">eg</span><span class="o">.</span><span class="n">save_embeddings</span><span class="p">(</span><span class="s1">'embeddings.csv'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1/300
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 493us/step - loss: 6.9202 - accuracy: 0.0100 - val_loss: 6.5489 - val_accuracy: 0.0160
2/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 6.4452 - accuracy: 0.0150 - val_loss: 6.3391 - val_accuracy: 0.0144
3/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 6.2737 - accuracy: 0.0172 - val_loss: 6.2418 - val_accuracy: 0.0142
4/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 6.2539 - accuracy: 0.0156 - val_loss: 6.1208 - val_accuracy: 0.0152
5/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 387us/step - loss: 6.1386 - accuracy: 0.0196 - val_loss: 6.1390 - val_accuracy: 0.0230
6/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 6.0841 - accuracy: 0.0170 - val_loss: 6.0209 - val_accuracy: 0.0210
7/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 6.0844 - accuracy: 0.0204 - val_loss: 5.9844 - val_accuracy: 0.0240
8/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 6.0329 - accuracy: 0.0222 - val_loss: 5.9625 - val_accuracy: 0.0244
9/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 6.0147 - accuracy: 0.0204 - val_loss: 5.9273 - val_accuracy: 0.0246
10/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 387us/step - loss: 5.9878 - accuracy: 0.0250 - val_loss: 5.9182 - val_accuracy: 0.0264
11/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 388us/step - loss: 5.9183 - accuracy: 0.0254 - val_loss: 5.8513 - val_accuracy: 0.0324
12/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 390us/step - loss: 5.9244 - accuracy: 0.0266 - val_loss: 5.8591 - val_accuracy: 0.0334
13/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 386us/step - loss: 5.8851 - accuracy: 0.0312 - val_loss: 5.8540 - val_accuracy: 0.0326
14/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 5.8685 - accuracy: 0.0316 - val_loss: 5.8123 - val_accuracy: 0.0378
15/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 5.8641 - accuracy: 0.0334 - val_loss: 5.8084 - val_accuracy: 0.0338
16/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 400us/step - loss: 5.8641 - accuracy: 0.0322 - val_loss: 5.7705 - val_accuracy: 0.0390
17/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 5.8240 - accuracy: 0.0434 - val_loss: 5.7161 - val_accuracy: 0.0510
18/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 387us/step - loss: 5.7978 - accuracy: 0.0442 - val_loss: 5.7052 - val_accuracy: 0.0492
19/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 384us/step - loss: 5.7698 - accuracy: 0.0396 - val_loss: 5.7139 - val_accuracy: 0.0484
20/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 5.7513 - accuracy: 0.0440 - val_loss: 5.6890 - val_accuracy: 0.0524
21/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 5.7090 - accuracy: 0.0488 - val_loss: 5.6584 - val_accuracy: 0.0514
22/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 5.7031 - accuracy: 0.0432 - val_loss: 5.5928 - val_accuracy: 0.0622
23/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 5.6509 - accuracy: 0.0554 - val_loss: 5.5568 - val_accuracy: 0.0670
24/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 381us/step - loss: 5.6746 - accuracy: 0.0600 - val_loss: 5.6020 - val_accuracy: 0.0604
25/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 390us/step - loss: 5.5880 - accuracy: 0.0618 - val_loss: 5.5072 - val_accuracy: 0.0756
26/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 5.6083 - accuracy: 0.0634 - val_loss: 5.5330 - val_accuracy: 0.0712
27/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 391us/step - loss: 5.5992 - accuracy: 0.0658 - val_loss: 5.5303 - val_accuracy: 0.0782
28/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 390us/step - loss: 5.5620 - accuracy: 0.0730 - val_loss: 5.4303 - val_accuracy: 0.0820
29/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 386us/step - loss: 5.5142 - accuracy: 0.0720 - val_loss: 5.3807 - val_accuracy: 0.0934
30/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 387us/step - loss: 5.5019 - accuracy: 0.0752 - val_loss: 5.3523 - val_accuracy: 0.0960
31/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 391us/step - loss: 5.4424 - accuracy: 0.0876 - val_loss: 5.3459 - val_accuracy: 0.0970
32/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 391us/step - loss: 5.4085 - accuracy: 0.0878 - val_loss: 5.3406 - val_accuracy: 0.1014
33/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 5.3886 - accuracy: 0.0888 - val_loss: 5.3043 - val_accuracy: 0.0976
34/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 393us/step - loss: 5.3653 - accuracy: 0.0924 - val_loss: 5.2621 - val_accuracy: 0.1140
35/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 388us/step - loss: 5.4007 - accuracy: 0.0890 - val_loss: 5.2699 - val_accuracy: 0.1140
36/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 5.2848 - accuracy: 0.1040 - val_loss: 5.2311 - val_accuracy: 0.1204
37/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 5.3042 - accuracy: 0.1008 - val_loss: 5.1873 - val_accuracy: 0.1230
38/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 5.2921 - accuracy: 0.1066 - val_loss: 5.1309 - val_accuracy: 0.1314
39/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 5.2618 - accuracy: 0.1070 - val_loss: 5.0953 - val_accuracy: 0.1448
40/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 390us/step - loss: 5.1676 - accuracy: 0.1136 - val_loss: 5.0245 - val_accuracy: 0.1492
41/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 389us/step - loss: 5.1354 - accuracy: 0.1242 - val_loss: 5.0307 - val_accuracy: 0.1498
42/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 5.1219 - accuracy: 0.1276 - val_loss: 4.9901 - val_accuracy: 0.1650
43/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 400us/step - loss: 5.1534 - accuracy: 0.1336 - val_loss: 4.9714 - val_accuracy: 0.1694
44/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 5.1184 - accuracy: 0.1376 - val_loss: 4.9489 - val_accuracy: 0.1592
45/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 5.0298 - accuracy: 0.1376 - val_loss: 4.9274 - val_accuracy: 0.1720
46/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 5.0099 - accuracy: 0.1504 - val_loss: 4.8445 - val_accuracy: 0.1786
47/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 4.9666 - accuracy: 0.1526 - val_loss: 4.7906 - val_accuracy: 0.1948
48/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 4.9227 - accuracy: 0.1608 - val_loss: 4.7955 - val_accuracy: 0.1882
49/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 4.9143 - accuracy: 0.1596 - val_loss: 4.7671 - val_accuracy: 0.1988
50/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 4.8729 - accuracy: 0.1662 - val_loss: 4.7239 - val_accuracy: 0.2054
51/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 394us/step - loss: 4.7912 - accuracy: 0.1836 - val_loss: 4.6844 - val_accuracy: 0.2136
52/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 393us/step - loss: 4.8110 - accuracy: 0.1784 - val_loss: 4.6213 - val_accuracy: 0.2212
53/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 4.6814 - accuracy: 0.1954 - val_loss: 4.5962 - val_accuracy: 0.2324
54/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 394us/step - loss: 4.7148 - accuracy: 0.1876 - val_loss: 4.5031 - val_accuracy: 0.2446
55/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 4.6427 - accuracy: 0.2044 - val_loss: 4.5063 - val_accuracy: 0.2494
56/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 394us/step - loss: 4.6296 - accuracy: 0.2088 - val_loss: 4.4856 - val_accuracy: 0.2628
57/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 389us/step - loss: 4.5943 - accuracy: 0.2136 - val_loss: 4.4382 - val_accuracy: 0.2612
58/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 394us/step - loss: 4.5594 - accuracy: 0.2218 - val_loss: 4.3101 - val_accuracy: 0.2852
59/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 4.5126 - accuracy: 0.2246 - val_loss: 4.3327 - val_accuracy: 0.2772
60/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 4.4381 - accuracy: 0.2378 - val_loss: 4.2424 - val_accuracy: 0.2890
61/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 388us/step - loss: 4.4603 - accuracy: 0.2266 - val_loss: 4.2749 - val_accuracy: 0.2970
62/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 4.4146 - accuracy: 0.2394 - val_loss: 4.1974 - val_accuracy: 0.3112
63/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 4.3489 - accuracy: 0.2488 - val_loss: 4.1782 - val_accuracy: 0.3094
64/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 4.3680 - accuracy: 0.2514 - val_loss: 4.1138 - val_accuracy: 0.3308
65/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 4.3094 - accuracy: 0.2558 - val_loss: 4.0360 - val_accuracy: 0.3318
66/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 4.2179 - accuracy: 0.2738 - val_loss: 4.0146 - val_accuracy: 0.3466
67/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 400us/step - loss: 4.1800 - accuracy: 0.2802 - val_loss: 3.9621 - val_accuracy: 0.3408
68/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 4.1356 - accuracy: 0.2862 - val_loss: 3.9211 - val_accuracy: 0.3626
69/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 390us/step - loss: 4.0549 - accuracy: 0.3104 - val_loss: 3.8791 - val_accuracy: 0.3770
70/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 4.0348 - accuracy: 0.3038 - val_loss: 3.8400 - val_accuracy: 0.3868
71/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 3.9944 - accuracy: 0.3064 - val_loss: 3.7690 - val_accuracy: 0.3856
72/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 4.0106 - accuracy: 0.3132 - val_loss: 3.7704 - val_accuracy: 0.3956
73/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 3.9379 - accuracy: 0.3204 - val_loss: 3.6701 - val_accuracy: 0.3974
74/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 3.8949 - accuracy: 0.3356 - val_loss: 3.6144 - val_accuracy: 0.4296
75/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 390us/step - loss: 3.8187 - accuracy: 0.3368 - val_loss: 3.5836 - val_accuracy: 0.4128
76/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 3.8102 - accuracy: 0.3428 - val_loss: 3.5028 - val_accuracy: 0.4346
77/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 3.7603 - accuracy: 0.3534 - val_loss: 3.4695 - val_accuracy: 0.4408
78/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 3.7149 - accuracy: 0.3650 - val_loss: 3.4650 - val_accuracy: 0.4510
79/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 392us/step - loss: 3.6468 - accuracy: 0.3808 - val_loss: 3.4893 - val_accuracy: 0.4436
80/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 3.6445 - accuracy: 0.3664 - val_loss: 3.3478 - val_accuracy: 0.4686
81/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 3.5365 - accuracy: 0.3988 - val_loss: 3.3008 - val_accuracy: 0.4854
82/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 3.5254 - accuracy: 0.3944 - val_loss: 3.3290 - val_accuracy: 0.4742
83/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 3.4863 - accuracy: 0.4056 - val_loss: 3.3257 - val_accuracy: 0.4792
84/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 3.4112 - accuracy: 0.4164 - val_loss: 3.1776 - val_accuracy: 0.5012
85/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 3.4042 - accuracy: 0.4216 - val_loss: 3.1592 - val_accuracy: 0.5088
86/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 3.2852 - accuracy: 0.4386 - val_loss: 3.1144 - val_accuracy: 0.5164
87/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 3.2709 - accuracy: 0.4408 - val_loss: 3.0742 - val_accuracy: 0.5240
88/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 3.2722 - accuracy: 0.4414 - val_loss: 3.0320 - val_accuracy: 0.5292
89/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 3.1894 - accuracy: 0.4532 - val_loss: 2.9413 - val_accuracy: 0.5480
90/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 3.1212 - accuracy: 0.4698 - val_loss: 2.8748 - val_accuracy: 0.5718
91/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 394us/step - loss: 3.0990 - accuracy: 0.4772 - val_loss: 2.9096 - val_accuracy: 0.5594
92/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 2.9949 - accuracy: 0.4906 - val_loss: 2.7876 - val_accuracy: 0.5796
93/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 2.9939 - accuracy: 0.4926 - val_loss: 2.7424 - val_accuracy: 0.5816
94/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 2.9415 - accuracy: 0.4980 - val_loss: 2.6546 - val_accuracy: 0.5992
95/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 2.9397 - accuracy: 0.5084 - val_loss: 2.6482 - val_accuracy: 0.5952
96/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 387us/step - loss: 2.8384 - accuracy: 0.5260 - val_loss: 2.6494 - val_accuracy: 0.6058
97/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 2.8045 - accuracy: 0.5276 - val_loss: 2.6678 - val_accuracy: 0.6152
98/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 2.7874 - accuracy: 0.5284 - val_loss: 2.5639 - val_accuracy: 0.6278
99/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 2.7609 - accuracy: 0.5396 - val_loss: 2.5057 - val_accuracy: 0.6398
100/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 2.6811 - accuracy: 0.5578 - val_loss: 2.4427 - val_accuracy: 0.6516
101/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 2.6871 - accuracy: 0.5456 - val_loss: 2.4066 - val_accuracy: 0.6654
102/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 2.5663 - accuracy: 0.5738 - val_loss: 2.3830 - val_accuracy: 0.6528
103/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 393us/step - loss: 2.5405 - accuracy: 0.5778 - val_loss: 2.2917 - val_accuracy: 0.6684
104/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 2.5373 - accuracy: 0.5870 - val_loss: 2.2606 - val_accuracy: 0.6852
105/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 2.4934 - accuracy: 0.5946 - val_loss: 2.2190 - val_accuracy: 0.6852
106/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 409us/step - loss: 2.4745 - accuracy: 0.5920 - val_loss: 2.1826 - val_accuracy: 0.6910
107/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 400us/step - loss: 2.3676 - accuracy: 0.6158 - val_loss: 2.1226 - val_accuracy: 0.7058
108/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 2.3591 - accuracy: 0.6148 - val_loss: 2.0710 - val_accuracy: 0.7092
109/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 2.3524 - accuracy: 0.6132 - val_loss: 2.0538 - val_accuracy: 0.7120
110/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 2.2083 - accuracy: 0.6440 - val_loss: 2.0058 - val_accuracy: 0.7246
111/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 2.2500 - accuracy: 0.6318 - val_loss: 1.9156 - val_accuracy: 0.7410
112/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 2.1819 - accuracy: 0.6530 - val_loss: 1.8126 - val_accuracy: 0.7542
113/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 2.0875 - accuracy: 0.6602 - val_loss: 1.8725 - val_accuracy: 0.7480
114/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 2.0695 - accuracy: 0.6694 - val_loss: 1.7876 - val_accuracy: 0.7560
115/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 1.9872 - accuracy: 0.6808 - val_loss: 1.7615 - val_accuracy: 0.7638
116/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 2.0265 - accuracy: 0.6764 - val_loss: 1.8029 - val_accuracy: 0.7500
117/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 395us/step - loss: 1.9593 - accuracy: 0.6968 - val_loss: 1.7222 - val_accuracy: 0.7694
118/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 1.9793 - accuracy: 0.6876 - val_loss: 1.7054 - val_accuracy: 0.7854
119/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 1.8934 - accuracy: 0.6984 - val_loss: 1.6764 - val_accuracy: 0.7760
120/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 411us/step - loss: 1.8731 - accuracy: 0.7044 - val_loss: 1.6600 - val_accuracy: 0.7762
121/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 1.8633 - accuracy: 0.7042 - val_loss: 1.5655 - val_accuracy: 0.7950
122/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 400us/step - loss: 1.8155 - accuracy: 0.7212 - val_loss: 1.5577 - val_accuracy: 0.8050
123/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 1.7936 - accuracy: 0.7226 - val_loss: 1.5797 - val_accuracy: 0.7924
124/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 400us/step - loss: 1.6727 - accuracy: 0.7428 - val_loss: 1.4695 - val_accuracy: 0.8170
125/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 1.6898 - accuracy: 0.7436 - val_loss: 1.4540 - val_accuracy: 0.8192
126/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 1.6531 - accuracy: 0.7418 - val_loss: 1.4008 - val_accuracy: 0.8206
127/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 399us/step - loss: 1.6137 - accuracy: 0.7506 - val_loss: 1.3895 - val_accuracy: 0.8118
128/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 1.6290 - accuracy: 0.7560 - val_loss: 1.3585 - val_accuracy: 0.8338
129/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 1.6117 - accuracy: 0.7524 - val_loss: 1.2903 - val_accuracy: 0.8374
130/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 411us/step - loss: 1.5511 - accuracy: 0.7594 - val_loss: 1.2891 - val_accuracy: 0.8316
131/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 396us/step - loss: 1.5014 - accuracy: 0.7786 - val_loss: 1.3013 - val_accuracy: 0.8308
132/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 1.4592 - accuracy: 0.7834 - val_loss: 1.2238 - val_accuracy: 0.8452
133/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 1.4994 - accuracy: 0.7738 - val_loss: 1.1824 - val_accuracy: 0.8542
134/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 1.4425 - accuracy: 0.7844 - val_loss: 1.1497 - val_accuracy: 0.8548
135/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 1.4319 - accuracy: 0.7870 - val_loss: 1.1830 - val_accuracy: 0.8530
136/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 405us/step - loss: 1.3450 - accuracy: 0.8006 - val_loss: 1.1152 - val_accuracy: 0.8616
137/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 1.4073 - accuracy: 0.7928 - val_loss: 1.1236 - val_accuracy: 0.8584
138/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 1.3359 - accuracy: 0.8014 - val_loss: 1.1054 - val_accuracy: 0.8554
139/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 1.3105 - accuracy: 0.8080 - val_loss: 1.0732 - val_accuracy: 0.8714
140/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 1.2528 - accuracy: 0.8166 - val_loss: 1.1127 - val_accuracy: 0.8648
141/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 1.2472 - accuracy: 0.8178 - val_loss: 1.0218 - val_accuracy: 0.8784
142/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 1.2278 - accuracy: 0.8228 - val_loss: 0.9639 - val_accuracy: 0.8844
143/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 1.2285 - accuracy: 0.8170 - val_loss: 1.0322 - val_accuracy: 0.8720
144/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 1.1853 - accuracy: 0.8240 - val_loss: 0.8959 - val_accuracy: 0.8954
145/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 1.1545 - accuracy: 0.8328 - val_loss: 0.9459 - val_accuracy: 0.8820
146/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 409us/step - loss: 1.1736 - accuracy: 0.8298 - val_loss: 0.9650 - val_accuracy: 0.8752
147/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 1.0828 - accuracy: 0.8468 - val_loss: 0.8727 - val_accuracy: 0.8946
148/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 1.0743 - accuracy: 0.8454 - val_loss: 0.8732 - val_accuracy: 0.8952
149/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 397us/step - loss: 1.1223 - accuracy: 0.8380 - val_loss: 0.8399 - val_accuracy: 0.8968
150/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 409us/step - loss: 1.0736 - accuracy: 0.8504 - val_loss: 0.8629 - val_accuracy: 0.8986
151/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 404us/step - loss: 1.0527 - accuracy: 0.8480 - val_loss: 0.7800 - val_accuracy: 0.9100
152/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 1.0271 - accuracy: 0.8550 - val_loss: 0.8736 - val_accuracy: 0.8946
153/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 401us/step - loss: 0.9801 - accuracy: 0.8648 - val_loss: 0.7773 - val_accuracy: 0.9082
154/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 398us/step - loss: 0.9624 - accuracy: 0.8606 - val_loss: 0.7587 - val_accuracy: 0.9122
155/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 0.9653 - accuracy: 0.8668 - val_loss: 0.7569 - val_accuracy: 0.9102
156/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 409us/step - loss: 0.9171 - accuracy: 0.8768 - val_loss: 0.7783 - val_accuracy: 0.9008
157/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 0.9824 - accuracy: 0.8598 - val_loss: 0.7716 - val_accuracy: 0.9114
158/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 0.9050 - accuracy: 0.8720 - val_loss: 0.6798 - val_accuracy: 0.9246
159/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 0.8868 - accuracy: 0.8782 - val_loss: 0.7305 - val_accuracy: 0.9134
160/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.8656 - accuracy: 0.8774 - val_loss: 0.6773 - val_accuracy: 0.9174
161/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 0.9094 - accuracy: 0.8732 - val_loss: 0.7563 - val_accuracy: 0.9078
162/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 408us/step - loss: 0.8625 - accuracy: 0.8852 - val_loss: 0.6772 - val_accuracy: 0.9216
163/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 411us/step - loss: 0.9143 - accuracy: 0.8728 - val_loss: 0.7034 - val_accuracy: 0.9154
164/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.8791 - accuracy: 0.8746 - val_loss: 0.7079 - val_accuracy: 0.9188
165/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 0.8265 - accuracy: 0.8880 - val_loss: 0.6240 - val_accuracy: 0.9240
166/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.7777 - accuracy: 0.8974 - val_loss: 0.6988 - val_accuracy: 0.9150
167/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 0.8305 - accuracy: 0.8876 - val_loss: 0.6100 - val_accuracy: 0.9274
168/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 0.7893 - accuracy: 0.8900 - val_loss: 0.6668 - val_accuracy: 0.9140
169/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.8148 - accuracy: 0.8926 - val_loss: 0.6679 - val_accuracy: 0.9230
170/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 0.7757 - accuracy: 0.8962 - val_loss: 0.6510 - val_accuracy: 0.9218
171/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 403us/step - loss: 0.7666 - accuracy: 0.8958 - val_loss: 0.5848 - val_accuracy: 0.9266
172/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.7406 - accuracy: 0.8994 - val_loss: 0.5751 - val_accuracy: 0.9296
173/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 0.7387 - accuracy: 0.8992 - val_loss: 0.5893 - val_accuracy: 0.9270
174/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 402us/step - loss: 0.7045 - accuracy: 0.9026 - val_loss: 0.5447 - val_accuracy: 0.9280
175/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.7532 - accuracy: 0.8990 - val_loss: 0.5440 - val_accuracy: 0.9338
176/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 0.7437 - accuracy: 0.9028 - val_loss: 0.5865 - val_accuracy: 0.9252
177/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 0.6795 - accuracy: 0.9090 - val_loss: 0.5411 - val_accuracy: 0.9344
178/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 411us/step - loss: 0.7007 - accuracy: 0.9012 - val_loss: 0.5581 - val_accuracy: 0.9260
179/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 0.6832 - accuracy: 0.9086 - val_loss: 0.5115 - val_accuracy: 0.9390
180/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 0.6835 - accuracy: 0.9100 - val_loss: 0.5173 - val_accuracy: 0.9446
181/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 0.6935 - accuracy: 0.9046 - val_loss: 0.5112 - val_accuracy: 0.9412
182/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 410us/step - loss: 0.7066 - accuracy: 0.9000 - val_loss: 0.5668 - val_accuracy: 0.9314
183/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 0.6225 - accuracy: 0.9148 - val_loss: 0.5051 - val_accuracy: 0.9388
184/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.6505 - accuracy: 0.9174 - val_loss: 0.5356 - val_accuracy: 0.9334
185/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 0.6816 - accuracy: 0.9102 - val_loss: 0.4791 - val_accuracy: 0.9428
186/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 0.6619 - accuracy: 0.9106 - val_loss: 0.5131 - val_accuracy: 0.9410
187/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 407us/step - loss: 0.6706 - accuracy: 0.9084 - val_loss: 0.5034 - val_accuracy: 0.9348
188/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 413us/step - loss: 0.6367 - accuracy: 0.9156 - val_loss: 0.4722 - val_accuracy: 0.9390
189/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 0.6209 - accuracy: 0.9154 - val_loss: 0.4924 - val_accuracy: 0.9394
190/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.5862 - accuracy: 0.9240 - val_loss: 0.4789 - val_accuracy: 0.9396
191/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 0.6070 - accuracy: 0.9210 - val_loss: 0.4566 - val_accuracy: 0.9392
192/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.5869 - accuracy: 0.9196 - val_loss: 0.4740 - val_accuracy: 0.9422
193/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.6011 - accuracy: 0.9222 - val_loss: 0.4707 - val_accuracy: 0.9468
194/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 412us/step - loss: 0.5858 - accuracy: 0.9198 - val_loss: 0.4336 - val_accuracy: 0.9468
195/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.5947 - accuracy: 0.9202 - val_loss: 0.4398 - val_accuracy: 0.9484
196/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.5615 - accuracy: 0.9256 - val_loss: 0.4687 - val_accuracy: 0.9408
197/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 0.5673 - accuracy: 0.9236 - val_loss: 0.4215 - val_accuracy: 0.9478
198/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 0.5637 - accuracy: 0.9294 - val_loss: 0.4343 - val_accuracy: 0.9456
199/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.6137 - accuracy: 0.9172 - val_loss: 0.4341 - val_accuracy: 0.9462
200/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.6006 - accuracy: 0.9218 - val_loss: 0.3884 - val_accuracy: 0.9512
201/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.5635 - accuracy: 0.9268 - val_loss: 0.4230 - val_accuracy: 0.9480
202/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 0.5658 - accuracy: 0.9256 - val_loss: 0.4512 - val_accuracy: 0.9440
203/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 0.6056 - accuracy: 0.9200 - val_loss: 0.4215 - val_accuracy: 0.9438
204/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.5344 - accuracy: 0.9278 - val_loss: 0.4380 - val_accuracy: 0.9458
205/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 0.5138 - accuracy: 0.9304 - val_loss: 0.3961 - val_accuracy: 0.9506
206/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 0.5704 - accuracy: 0.9264 - val_loss: 0.3948 - val_accuracy: 0.9486
207/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.5551 - accuracy: 0.9248 - val_loss: 0.3943 - val_accuracy: 0.9526
208/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.4828 - accuracy: 0.9366 - val_loss: 0.4855 - val_accuracy: 0.9334
209/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 0.4814 - accuracy: 0.9376 - val_loss: 0.3574 - val_accuracy: 0.9580
210/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.4560 - accuracy: 0.9418 - val_loss: 0.4189 - val_accuracy: 0.9474
211/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 417us/step - loss: 0.5182 - accuracy: 0.9278 - val_loss: 0.3576 - val_accuracy: 0.9526
212/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 416us/step - loss: 0.4829 - accuracy: 0.9360 - val_loss: 0.3724 - val_accuracy: 0.9542
213/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.5509 - accuracy: 0.9252 - val_loss: 0.4110 - val_accuracy: 0.9492
214/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.5758 - accuracy: 0.9202 - val_loss: 0.4106 - val_accuracy: 0.9498
215/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 440us/step - loss: 0.4821 - accuracy: 0.9340 - val_loss: 0.3331 - val_accuracy: 0.9600
216/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 0.4816 - accuracy: 0.9352 - val_loss: 0.3872 - val_accuracy: 0.9562
217/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 0.4919 - accuracy: 0.9354 - val_loss: 0.3316 - val_accuracy: 0.9600
218/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 0.4545 - accuracy: 0.9382 - val_loss: 0.3393 - val_accuracy: 0.9538
219/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 0.4772 - accuracy: 0.9376 - val_loss: 0.3637 - val_accuracy: 0.9542
220/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 0.4726 - accuracy: 0.9400 - val_loss: 0.3490 - val_accuracy: 0.9598
221/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 440us/step - loss: 0.4793 - accuracy: 0.9378 - val_loss: 0.3734 - val_accuracy: 0.9488
222/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 0.5026 - accuracy: 0.9352 - val_loss: 0.3776 - val_accuracy: 0.9526
223/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.4759 - accuracy: 0.9306 - val_loss: 0.3640 - val_accuracy: 0.9504
224/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 0.4789 - accuracy: 0.9378 - val_loss: 0.3393 - val_accuracy: 0.9588
225/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.4675 - accuracy: 0.9372 - val_loss: 0.3774 - val_accuracy: 0.9558
226/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.5579 - accuracy: 0.9288 - val_loss: 0.3467 - val_accuracy: 0.9576
227/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.4209 - accuracy: 0.9410 - val_loss: 0.3965 - val_accuracy: 0.9468
228/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.4648 - accuracy: 0.9406 - val_loss: 0.3432 - val_accuracy: 0.9578
229/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.5176 - accuracy: 0.9314 - val_loss: 0.3913 - val_accuracy: 0.9500
230/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.4967 - accuracy: 0.9360 - val_loss: 0.3768 - val_accuracy: 0.9560
231/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 0.4823 - accuracy: 0.9396 - val_loss: 0.3141 - val_accuracy: 0.9628
232/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 0.4552 - accuracy: 0.9438 - val_loss: 0.3027 - val_accuracy: 0.9600
233/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 0.4230 - accuracy: 0.9444 - val_loss: 0.3282 - val_accuracy: 0.9578
234/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.4708 - accuracy: 0.9340 - val_loss: 0.3755 - val_accuracy: 0.9472
235/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.4087 - accuracy: 0.9416 - val_loss: 0.3489 - val_accuracy: 0.9550
236/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 0.4523 - accuracy: 0.9386 - val_loss: 0.3294 - val_accuracy: 0.9594
237/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.4482 - accuracy: 0.9392 - val_loss: 0.3893 - val_accuracy: 0.9538
238/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.4506 - accuracy: 0.9400 - val_loss: 0.3563 - val_accuracy: 0.9530
239/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 406us/step - loss: 0.4631 - accuracy: 0.9388 - val_loss: 0.3517 - val_accuracy: 0.9570
240/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 0.4394 - accuracy: 0.9492 - val_loss: 0.2732 - val_accuracy: 0.9688
241/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.4131 - accuracy: 0.9440 - val_loss: 0.3108 - val_accuracy: 0.9628
242/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 0.4081 - accuracy: 0.9440 - val_loss: 0.3488 - val_accuracy: 0.9532
243/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 415us/step - loss: 0.4218 - accuracy: 0.9440 - val_loss: 0.3199 - val_accuracy: 0.9612
244/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 414us/step - loss: 0.4196 - accuracy: 0.9452 - val_loss: 0.3118 - val_accuracy: 0.9610
245/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.3984 - accuracy: 0.9474 - val_loss: 0.3152 - val_accuracy: 0.9612
246/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.4311 - accuracy: 0.9400 - val_loss: 0.2962 - val_accuracy: 0.9634
247/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 0.4427 - accuracy: 0.9402 - val_loss: 0.3643 - val_accuracy: 0.9556
248/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 0.4436 - accuracy: 0.9410 - val_loss: 0.3296 - val_accuracy: 0.9612
249/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 0.4356 - accuracy: 0.9440 - val_loss: 0.3044 - val_accuracy: 0.9630
250/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.3828 - accuracy: 0.9490 - val_loss: 0.2771 - val_accuracy: 0.9684
251/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.4115 - accuracy: 0.9416 - val_loss: 0.3557 - val_accuracy: 0.9580
252/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 0.3686 - accuracy: 0.9490 - val_loss: 0.3319 - val_accuracy: 0.9634
253/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.4639 - accuracy: 0.9432 - val_loss: 0.2853 - val_accuracy: 0.9638
254/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 437us/step - loss: 0.4792 - accuracy: 0.9362 - val_loss: 0.3423 - val_accuracy: 0.9564
255/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 0.4066 - accuracy: 0.9480 - val_loss: 0.3347 - val_accuracy: 0.9576
256/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 428us/step - loss: 0.4724 - accuracy: 0.9376 - val_loss: 0.2919 - val_accuracy: 0.9658
257/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 0.4215 - accuracy: 0.9410 - val_loss: 0.2725 - val_accuracy: 0.9642
258/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 425us/step - loss: 0.4419 - accuracy: 0.9464 - val_loss: 0.3282 - val_accuracy: 0.9636
259/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 420us/step - loss: 0.4133 - accuracy: 0.9474 - val_loss: 0.2633 - val_accuracy: 0.9680
260/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.4547 - accuracy: 0.9410 - val_loss: 0.3277 - val_accuracy: 0.9632
261/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 0.3550 - accuracy: 0.9518 - val_loss: 0.2824 - val_accuracy: 0.9662
262/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 0.4278 - accuracy: 0.9406 - val_loss: 0.2624 - val_accuracy: 0.9686
263/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 437us/step - loss: 0.4622 - accuracy: 0.9398 - val_loss: 0.3406 - val_accuracy: 0.9556
264/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 0.3704 - accuracy: 0.9546 - val_loss: 0.3197 - val_accuracy: 0.9664
265/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 0.3736 - accuracy: 0.9492 - val_loss: 0.3204 - val_accuracy: 0.9618
266/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.3926 - accuracy: 0.9480 - val_loss: 0.3420 - val_accuracy: 0.9558
267/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 426us/step - loss: 0.3492 - accuracy: 0.9552 - val_loss: 0.3409 - val_accuracy: 0.9594
268/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 424us/step - loss: 0.4315 - accuracy: 0.9456 - val_loss: 0.3871 - val_accuracy: 0.9564
269/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 438us/step - loss: 0.4241 - accuracy: 0.9416 - val_loss: 0.3569 - val_accuracy: 0.9562
270/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 0.4078 - accuracy: 0.9438 - val_loss: 0.2925 - val_accuracy: 0.9646
271/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 419us/step - loss: 0.3924 - accuracy: 0.9468 - val_loss: 0.3646 - val_accuracy: 0.9536
272/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 0.3643 - accuracy: 0.9520 - val_loss: 0.3494 - val_accuracy: 0.9608
273/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 418us/step - loss: 0.3252 - accuracy: 0.9564 - val_loss: 0.2771 - val_accuracy: 0.9666
274/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.4002 - accuracy: 0.9480 - val_loss: 0.3212 - val_accuracy: 0.9644
275/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.4312 - accuracy: 0.9450 - val_loss: 0.3275 - val_accuracy: 0.9604
276/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.4204 - accuracy: 0.9418 - val_loss: 0.2861 - val_accuracy: 0.9620
277/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.4327 - accuracy: 0.9462 - val_loss: 0.2808 - val_accuracy: 0.9636
278/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 0.4367 - accuracy: 0.9428 - val_loss: 0.3191 - val_accuracy: 0.9568
279/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.3983 - accuracy: 0.9492 - val_loss: 0.3552 - val_accuracy: 0.9592
280/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 432us/step - loss: 0.3887 - accuracy: 0.9472 - val_loss: 0.2665 - val_accuracy: 0.9658
281/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.3997 - accuracy: 0.9486 - val_loss: 0.2733 - val_accuracy: 0.9666
282/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.3756 - accuracy: 0.9484 - val_loss: 0.2950 - val_accuracy: 0.9626
283/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 430us/step - loss: 0.3351 - accuracy: 0.9502 - val_loss: 0.2685 - val_accuracy: 0.9652
284/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.3385 - accuracy: 0.9566 - val_loss: 0.2542 - val_accuracy: 0.9664
285/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 446us/step - loss: 0.3217 - accuracy: 0.9572 - val_loss: 0.3173 - val_accuracy: 0.9628
286/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 0.3968 - accuracy: 0.9494 - val_loss: 0.3565 - val_accuracy: 0.9536
287/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 434us/step - loss: 0.4626 - accuracy: 0.9386 - val_loss: 0.3295 - val_accuracy: 0.9590
288/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 436us/step - loss: 0.3845 - accuracy: 0.9450 - val_loss: 0.3039 - val_accuracy: 0.9630
289/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.4553 - accuracy: 0.9394 - val_loss: 0.2742 - val_accuracy: 0.9644
290/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 423us/step - loss: 0.4083 - accuracy: 0.9486 - val_loss: 0.2771 - val_accuracy: 0.9692
291/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 447us/step - loss: 0.3854 - accuracy: 0.9468 - val_loss: 0.3103 - val_accuracy: 0.9640
292/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 429us/step - loss: 0.3969 - accuracy: 0.9484 - val_loss: 0.2863 - val_accuracy: 0.9642
293/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 435us/step - loss: 0.3743 - accuracy: 0.9508 - val_loss: 0.2994 - val_accuracy: 0.9654
294/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 431us/step - loss: 0.3768 - accuracy: 0.9484 - val_loss: 0.3063 - val_accuracy: 0.9620
295/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 422us/step - loss: 0.3746 - accuracy: 0.9496 - val_loss: 0.3148 - val_accuracy: 0.9662
296/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 421us/step - loss: 0.3738 - accuracy: 0.9516 - val_loss: 0.2518 - val_accuracy: 0.9680
297/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 427us/step - loss: 0.3634 - accuracy: 0.9562 - val_loss: 0.3113 - val_accuracy: 0.9608
298/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 433us/step - loss: 0.3427 - accuracy: 0.9530 - val_loss: 0.3012 - val_accuracy: 0.9556
299/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 437us/step - loss: 0.3641 - accuracy: 0.9508 - val_loss: 0.2865 - val_accuracy: 0.9550
300/300
Train on 5000 samples, validate on 5000 samples
Epoch 1/1
5000/5000 [==============================] - 2s 439us/step - loss: 0.3436 - accuracy: 0.9544 - val_loss: 0.2552 - val_accuracy: 0.9686
100000/100000 [==============================] - 10s 101us/step
Train set: Loss=0.2559 ; Accuracy=96.9%
100000/100000 [==============================] - 10s 101us/step
Test set: Loss=14.9620 ; Accuracy=1.8%
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-embeddings">
<a class="anchor" href="#Load-embeddings" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load embeddings<a class="anchor-link" href="#Load-embeddings"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">Embeddings</span><span class="p">(</span><span class="n">read_embeddings</span><span class="p">(</span><span class="s1">'embeddings.csv'</span><span class="p">))</span>

<span class="n">state_space_size</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">*</span> <span class="n">history_length</span>
<span class="n">action_space_size</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">*</span> <span class="n">ra_length</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Start-Agent-training">
<a class="anchor" href="#Start-Agent-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Start Agent training<a class="anchor-link" href="#Start-Agent-training"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">environment</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">fixed_length</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span> <span class="c1"># For multiple consecutive executions</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="c1"># '1: Initialize actor network f_Î¸^Ï€ and critic network Q(s, a|Î¸^Âµ) with random weights'</span>
<span class="n">actor</span> <span class="o">=</span> <span class="n">Actor</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">tau</span><span class="p">,</span> <span class="n">actor_lr</span><span class="p">)</span>
<span class="n">critic</span> <span class="o">=</span> <span class="n">Critic</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">state_space_size</span><span class="p">,</span> <span class="n">action_space_size</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">tau</span><span class="p">,</span> <span class="n">critic_lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">environment</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">discount_factor</span><span class="p">,</span> <span class="n">nb_episodes</span><span class="p">,</span> <span class="n">filename_summary</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From &lt;ipython-input-19-1a5cd2de5f02&gt;:69: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From &lt;ipython-input-19-1a5cd2de5f02&gt;:70: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
WARNING:tensorflow:From &lt;ipython-input-19-1a5cd2de5f02&gt;:40: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Episode 1/100 Reward=552 Time=4s No replay
Episode 2/100 Reward=551 Time=52s Loss=2082.7095
Episode 3/100 Reward=551 Time=68s Loss=123.3409
Episode 4/100 Reward=551 Time=67s Loss=67.4848
Episode 5/100 Reward=551 Time=67s Loss=44.0779
Episode 6/100 Reward=552 Time=67s Loss=40.3507
Episode 7/100 Reward=552 Time=67s Loss=29.4237
Episode 8/100 Reward=552 Time=68s Loss=26.5713
Episode 9/100 Reward=552 Time=68s Loss=27.1646
Episode 10/100 Reward=552 Time=68s Loss=25.9928
Episode 11/100 Reward=552 Time=67s Loss=22.3598
Episode 12/100 Reward=552 Time=68s Loss=18.7026
Episode 13/100 Reward=552 Time=67s Loss=17.8249
Episode 14/100 Reward=551 Time=67s Loss=19.8687
Episode 15/100 Reward=552 Time=68s Loss=20.9238
Episode 16/100 Reward=551 Time=67s Loss=19.9583
Episode 17/100 Reward=551 Time=68s Loss=20.2933
Episode 18/100 Reward=551 Time=67s Loss=19.9462
Episode 19/100 Reward=551 Time=67s Loss=24.3696
Episode 20/100 Reward=551 Time=67s Loss=25.6828
Episode 21/100 Reward=551 Time=67s Loss=28.5111
Episode 22/100 Reward=551 Time=67s Loss=29.4505
Episode 23/100 Reward=551 Time=67s Loss=27.2863
Episode 24/100 Reward=551 Time=68s Loss=28.4667
Episode 25/100 Reward=551 Time=67s Loss=26.7666
Episode 26/100 Reward=551 Time=67s Loss=26.2378
Episode 27/100 Reward=551 Time=67s Loss=25.0391
Episode 28/100 Reward=551 Time=67s Loss=25.0170
Episode 29/100 Reward=551 Time=68s Loss=22.9655
Episode 30/100 Reward=551 Time=68s Loss=23.8730
Episode 31/100 Reward=551 Time=67s Loss=20.4020
Episode 32/100 Reward=551 Time=67s Loss=22.4662
Episode 33/100 Reward=551 Time=67s Loss=23.8943
Episode 34/100 Reward=551 Time=67s Loss=21.1020
Episode 35/100 Reward=551 Time=67s Loss=22.8528
Episode 36/100 Reward=551 Time=67s Loss=21.2307
Episode 37/100 Reward=551 Time=67s Loss=19.7094
Episode 38/100 Reward=551 Time=67s Loss=21.4233
Episode 39/100 Reward=551 Time=67s Loss=23.6903
Episode 40/100 Reward=551 Time=67s Loss=24.4852
Episode 41/100 Reward=551 Time=67s Loss=25.7120
Episode 42/100 Reward=551 Time=67s Loss=21.7722
Episode 43/100 Reward=551 Time=67s Loss=20.9898
Episode 44/100 Reward=551 Time=67s Loss=20.6604
Episode 45/100 Reward=551 Time=68s Loss=20.8646
Episode 46/100 Reward=551 Time=67s Loss=19.4622
Episode 47/100 Reward=551 Time=67s Loss=20.4751
Episode 48/100 Reward=551 Time=67s Loss=18.9989
Episode 49/100 Reward=551 Time=67s Loss=17.7407
Episode 50/100 Reward=551 Time=67s Loss=17.3576
Episode 51/100 Reward=551 Time=68s Loss=17.2397
Episode 52/100 Reward=552 Time=67s Loss=16.5722
Episode 53/100 Reward=552 Time=67s Loss=15.5511
Episode 54/100 Reward=552 Time=67s Loss=15.7651
Episode 55/100 Reward=552 Time=67s Loss=14.0308
Episode 56/100 Reward=552 Time=67s Loss=14.4518
Episode 57/100 Reward=551 Time=67s Loss=15.9018
Episode 58/100 Reward=552 Time=67s Loss=14.2520
Episode 59/100 Reward=551 Time=67s Loss=14.2282
Episode 60/100 Reward=551 Time=67s Loss=14.1576
Episode 61/100 Reward=551 Time=67s Loss=13.1366
Episode 62/100 Reward=551 Time=67s Loss=13.7383
Episode 63/100 Reward=551 Time=67s Loss=12.3095
Episode 64/100 Reward=551 Time=68s Loss=11.7993
Episode 65/100 Reward=551 Time=67s Loss=12.1072
Episode 66/100 Reward=551 Time=67s Loss=12.8614
Episode 67/100 Reward=552 Time=67s Loss=11.4739
Episode 68/100 Reward=552 Time=67s Loss=12.6560
Episode 69/100 Reward=552 Time=67s Loss=12.8773
Episode 70/100 Reward=552 Time=67s Loss=11.7954
Episode 71/100 Reward=552 Time=67s Loss=11.2212
Episode 72/100 Reward=552 Time=67s Loss=12.3400
Episode 73/100 Reward=552 Time=67s Loss=12.5248
Episode 74/100 Reward=552 Time=67s Loss=11.2045
Episode 75/100 Reward=552 Time=67s Loss=11.1089
Episode 76/100 Reward=552 Time=67s Loss=11.6253
Episode 77/100 Reward=552 Time=67s Loss=10.9183
Episode 78/100 Reward=552 Time=67s Loss=9.2532
Episode 79/100 Reward=552 Time=67s Loss=10.4258
Episode 80/100 Reward=552 Time=67s Loss=10.0044
Episode 81/100 Reward=552 Time=67s Loss=10.4150
Episode 82/100 Reward=552 Time=67s Loss=10.9766
Episode 83/100 Reward=551 Time=67s Loss=8.8571
Episode 84/100 Reward=551 Time=67s Loss=10.5467
Episode 85/100 Reward=551 Time=67s Loss=8.8356
Episode 86/100 Reward=551 Time=67s Loss=11.0192
Episode 87/100 Reward=551 Time=67s Loss=9.3348
Episode 88/100 Reward=551 Time=67s Loss=11.0042
Episode 89/100 Reward=551 Time=67s Loss=8.5757
Episode 90/100 Reward=551 Time=67s Loss=8.8545
Episode 91/100 Reward=551 Time=67s Loss=10.0286
Episode 92/100 Reward=551 Time=67s Loss=10.2471
Episode 93/100 Reward=551 Time=67s Loss=9.3180
Episode 94/100 Reward=551 Time=68s Loss=8.2303
Episode 95/100 Reward=551 Time=68s Loss=9.1910
Episode 96/100 Reward=551 Time=67s Loss=8.2708
Episode 97/100 Reward=551 Time=67s Loss=8.1502
Episode 98/100 Reward=551 Time=67s Loss=8.1103
Episode 99/100 Reward=551 Time=67s Loss=8.2638
Episode 100/100 Reward=551 Time=67s Loss=8.2967
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Testing">
<a class="anchor" href="#Testing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Testing<a class="anchor-link" href="#Testing"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">dict_embeddings</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get_embedding_vector</span><span class="p">()):</span>
  <span class="n">str_item</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
  <span class="k">assert</span><span class="p">(</span><span class="n">str_item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dict_embeddings</span><span class="p">)</span>
  <span class="n">dict_embeddings</span><span class="p">[</span><span class="n">str_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">state_to_items</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">dict_embeddings</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)]</span>
          <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actor</span><span class="o">.</span><span class="n">get_recommendation_list</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">test_actor</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">test_df</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nb_rounds</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">ratings</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">unknown</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">random_seen</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_rounds</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">)):</span>
      <span class="n">history_sample</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">history_length</span><span class="p">)[</span><span class="s1">'itemId'</span><span class="p">])</span>
      <span class="n">recommendation</span> <span class="o">=</span> <span class="n">state_to_items</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">history_sample</span><span class="p">),</span> <span class="n">actor</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">recommendation</span><span class="p">:</span>
        <span class="n">l</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">'itemId'</span><span class="p">]</span> <span class="o">==</span> <span class="n">item</span><span class="p">][</span><span class="s1">'rating'</span><span class="p">])</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">unknown</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">ratings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">history_sample</span><span class="p">:</span>
        <span class="n">random_seen</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_df</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">'itemId'</span><span class="p">]</span> <span class="o">==</span> <span class="n">item</span><span class="p">][</span><span class="s1">'rating'</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">ratings</span><span class="p">,</span> <span class="n">unknown</span><span class="p">,</span> <span class="n">random_seen</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-1---Trainset-and-target=False">
<a class="anchor" href="#Test-1---Trainset-and-target=False" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test 1 - Trainset and target=False<a class="anchor-link" href="#Test-1---Trainset-and-target=False"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ratings</span><span class="p">,</span> <span class="n">unknown</span><span class="p">,</span> <span class="n">random_seen</span> <span class="o">=</span> <span class="n">test_actor</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nb_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%0.1f%%</span><span class="s1"> unknown'</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">unknown</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span> <span class="o">+</span> <span class="n">unknown</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>91.5% unknown
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Predictions ; Mean = </span><span class="si">%.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratings</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Random ; Mean = </span><span class="si">%.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-2---Trainset-and-target=True">
<a class="anchor" href="#Test-2---Trainset-and-target=True" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test 2 - Trainset and target=True<a class="anchor-link" href="#Test-2---Trainset-and-target=True"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ratings</span><span class="p">,</span> <span class="n">unknown</span><span class="p">,</span> <span class="n">random_seen</span> <span class="o">=</span> <span class="n">test_actor</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">dg</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">dict_embeddings</span><span class="p">,</span> <span class="n">ra_length</span><span class="p">,</span> <span class="n">history_length</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nb_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%0.1f%%</span><span class="s1"> unknown'</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">unknown</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span> <span class="o">+</span> <span class="n">unknown</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>91.5% unknown
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ratings</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Predictions ; Mean = </span><span class="si">%.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratings</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Random ; Mean = </span><span class="si">%.4f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">random_seen</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAsUAAAF1CAYAAAAA6ZfwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xddX3n/9fbhIuKGoSUYpIaRqgWHQWaAo62PwojV2toixZqJTgoWmHU0WmNdixVsT/sw4pj62XQ8BO8IT/UklEspYhtmRmRIMi1SERoknKJ3L03+Jk/1vfI5nhOcpKcs89O1uv5eOxH1v5+v2ut71pJvvu91/7utVNVSJIkSX32uNnugCRJkjTbDMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUNxzyT5eJIz2vKvJ7llC7fzkSRvn97eSZK2VpI/S/LJ2e6HtK0xFI+gJLcn+WGS7yW5uwXZXaZ7P1X1T1X1zCn056QkV4xb97VV9a7p7tOWSnJIkkryhXHlz2vlX52lrm22JH+RZE2Sh5LckeRtG2mbJH+S5F9a+/OTPHmgfkGSi5Lcl2RtkteOW39OkjOS/GuSh5Nck2Req3tOkkuSfDeJNzSXtsK4cf2umRrXR0l77agkZ40rX9rKPz5LXdtsST6Z5M42zn4ryas20vakJI+0v+uxxyED9fsl+ackD7Zx+e0DdTsmubD9e6nB9Vr9HyW5oY3X30nyRzNxvH1lKB5dv1VVuwAHAEuA/za+QZK5Q+/VaFsPPD/JbgNly4BvzVJ/ttQK4FlV9WTgPwAvT/I7k7Q9EXgF8ALgacDjgb8aqP8k8B1gD+AY4M+T/OZA/TvaPp4PPLlt60et7t+AC4CTp+GYJD06ru8H7A+8dZb7MwzfBl427vVqWxyX/19gcRuXXwKckeRXN9L+/1TVLgOPrw7UfRr4R+CpwP8DvC7JSwbqrwD+ALhrgu2GbtzfFTgSOC3J8Vt6UHosQ/GIq6p1wJeB5wC0d46nJrkVuLWVvTjJtUkeSPK/kzx3bP0k+yf5RntX+Vlg54G6Q5KsHXi+KMnnk6xPcm+Sv07yK8BH6MLm95I80Nr+bBpGe/7qJKvbFcmVSZ42UFdJXpvk1tbHDyZJq9s7yT+0d8zfbX2cUJLrkvz+Rk7XT4C/AY5v7ecAvwd8atx2npXk0tbXW5K8bKDumHa19KF2tfbPBuoWt2NZ1q7MfjfJn2ykP1ukqm6pqu8PFP0U2HuS5r8FrKiqNVX1PeA9wO8leUK7CnUI8O6q+req+iZwIfCf2vHsCrwReHVV3VGdG6rqRwP9WAHcON3HKPVZVd0FXEIXjgFIsjzJt9tYfVOS3x6oOynJFUnem+T+doXwqIH6vdo4+nCSS4HdB/eX5CVJbmzj71fbuD5Wd3u7+nhdku8nWZFkjyRfbtv7+zZWTKht84UbOdy7gOuBI1r7p9K9EV85bjsHt9evB5J8c9yV1Vcmubn157YkrxmoOyTd1dY3J7kn3dXcV26kP1ukqm6sqh+PPW2PZ2zh5hYDn6qqR6rq23Qh+NltPz+pqvdX1RXAIxP04y+q6htVtaGqbgEuorsoomlgKB5xSRYBRwPXDBQfCxwE7Jtkf+Ac4DXAbsD/AFYm2SnJjnQh8RN070j/f+B3J9nPHOCLwB10/2EXAOdX1c3Aa3n0Xe+8CdY9lO5d9MuAPds2zh/X7MXArwHPbe2OaOXvAv6O7l3vQh57lfMxquq5VfXpyeqb8+jeRdP2cQPwrwN9fSJwKd079V+gC9AfSrJva/L9tv48uiurf5jk2HH7eCHwTOAw4E8HX2AGtRe5ByZ7bOwg2rrfA9YCT2z9nbT5uOWdgH0GysfXP6ct/3tgA3Bcuo9zv5Xk1I31S9LWS7IQOApYPVD8beDXgafQfYLzySR7DtQfBNxCF3j/AlgxdnGBbny4utW9i+5K7Ni+fhn4DN0b4PnAxcD/bK8PY34XeBHwy3RvtL8MvK21fxzw+smOparmtQC3MYPj8vF0QW4sYJJkAfAl4Ay616r/CnwuyfzW5B6615AnA68EzkpywMD2f5HuvC2g+2Trg5MF+SQf2si4fN3GDqKt+wPgn4E76c7lZPZvF06+leTteeyV8vcDJybZIckz6T6p+/uN7XuS/oTu34wXLqZLVfkYsQdwO/A94AG6gPkh4PGtroBDB9p+GHjXuPVvoftI5jfoAmEG6v43cEZbPgRY25afTzf9YO4E/TkJuGJc2ccHtrMC+IuBul3oPnpfPNDnFw7UXwAsb8vnAWcDC7fynA0ey610ofV84OXAq4CvtrrfA/5p3Lr/Azh9ku2+HzirLS9ux7JwoP7rwPEz9O8gdB+xvgN40iRtXkX3MeRiuheFla2Pz2/1V9C90diZbirOfcAtre73W9sVdNMuntv+Dbxo3D727oaK2f+/4cPHtvoYGNcfbv/vLgPmbaT9tcDStnwSsHqg7gltG78I/BLdm9snDtR/GvhkW347cMFA3eOAdcAhA/16+UD954APDzz/z8DfbOExn9TGoMcDd7cx6mt0VzbPAD7e2r0F+MS4dS8Blk2y3b8B3tCWDwF+yMBrF12IPniG/h7n0F0Y+W/ADpO0+XfAXu1c/3vgJuCtA/X/ge4N0Yb29/iOSbazduzvaZL6dwDfBHaa7X/f28vDK8Wj69jq3oE/vapeV1U/HKhbM7D8dODN465ALqKbX/o0YF21/z3NHZPsbxFwR1Vt2IK+Pm1wu9V9jH8v3bv2MYNzo35AF5wB/pgu/H29fbz3n7Zg/+N9AjgN+E3gC+Pqng4cNO58vZzuxYUkByW5PN0UkgfprpLvPm4bkx3LtKrONXQD/jsmaXYO3VWgr9JdLbi8lY9Ni3k53eC8hu4N1CcH6sb+Tb2zqn5YVdfRvZE4ehoPQ9Kjjq2qJ9EFuWcxMLYkOTGPToN7gO4TncGx52fjTlX9oC3uQjf+3l+PnXI1OM6PH59/SjceDI7Pdw8s/3CC51s1xrXXry/RBcndqup/jWvydOCl48blF9J98kiSo5J8Ld2UtwfoxqjBc3PvuNeumRyXH6nuyvhC4A8naXNbVX2nqn5aVdcD7wSOa8fyVOBvW9nOdK+9RyR53eb0I8lpdFffj6lHp3VoKxmKt02DIXcN3ZzReQOPJ1TVZ+g+3lkw8BEbdFcVJrIG+KVM/OW9Td154F/pBjXgZ1MUdqO7GrHxA6m6q6peXVVPo5sC8qEkk82fnapPAK8DLh548RizBviHcedrl6oaG9w+TXe1dVFVPYVuPnXYAknelsd++/gxj83Y1FwmmbvWBt3Tq2pxVS2kC8br2oPq5gq/uKrmV9VBdC8kX2+rj31UOPj3610mpBlWVf9A92nbewGSPB34KN2b+d2qm6Z2A1Mbe+4Edm3j7pjBcX78+By6ILbJ8XmanQe8me6N+Xhr6K4UD47LT6yqM5PsRHf1+r3AHu3cXMyWj8sf2ci4vDnTECYdlydQPNrffwc8UlXnVTcveC2beTGiXTxaDhzW1tc0MRRv+z4KvLZd4UySJ6b7stiTgP9D9/HM69vcpd8BDpxkO1+nG1zPbNvYOcnY5P27gYXj5qAN+gzwynS3mdkJ+HPgyqq6fVOdT/LSNr8O4H66weOnk7S9PclJm9pmVX2HbvrIRF+C+yLwy0le0c7JDkl+bWBe8JOA+6rqR0kOpJtisEWq6s/rsd8+fsxjonWSPC7Ja5Ls2v4+DwROpfuodaL2T03yjNZ2X+B9dFd+f9rqfyXJk9Ld5ucPgMNbG6r7gsc/AX+Sbg76r9DN9/tiWzdJdgZ2bM93bn+/krbe+4EXJXke3fcGim76Eum+KPacjaz7M1V1B7AKeEf7f/5CunnBYy4AjklyWJId6ILpj+mm0m21THDbsEn8A9285Ym+N/JJ4LeSHJHuNpE7p/sC3UK68WcnunOzId0XDA/f0v5WdzvRycblZ0+0TpJfSHJ8kl1a/44ATmDycfmoJHu05WfRTWG5qFV/qyvO77fx/hfppvVdN7D+Tm3sBdixnY+xL6e/nO419kVVdduWngdNzFC8jauqVcCrgb+mC5Wr6eZxUVU/AX6nPb+P7j/e5yfZziN0A+newL/QfcT+e636K3RXIO9K8t0J1v17uv/0n6ML1s+g3QFiCn4NuLJdOV1JN0/s5/6jt0C+G918tE2qqiuq6l8nKH+YbkA9nu4Kyl10d2wYC3uvA96Z5GHgT+leUIbtt+m+dPMw3YvFXzHwQtKuaPx6e7o73VWT79N9Oeacqjp7YFtHALfR/dt4LXBkVa0fqD+B7irSvXQfb769qsYG+qfTfXQ6dvXkh3Tz1SVtpfb/8DzgT6vqJuAv6S5k3E03D3X8FION+X26L+LdB5zetju2n1vobu/1V8B36cb532qvD1sl3RfBH6a7u8RGtelgl1XVfRPUrQGW0n25bz3dleM/Ah7XxuzX043F99Md68rx25hhRTdVYm3rw3uBN1bVSoAkv9TG5bEr9IcB1yX5Pt34/Hm6IEtVPUT3uvxf2raupftU4IxHd8ctdOPtArq51T/k0av9Z9C9Fl41cIX7IzNy1D2Ux043lUZTu/pxalWdMNt9kSRB+/Tp2VXVh/stqwcMxZIkSeo9p09IkiSp9wzFkiRJ6j1DsSRJknrPUCxJkqTem+iHGoZu9913r8WLF892NyRps1199dXfrar5s92PYXLMlrQtm2zcHolQvHjxYlatWjXb3ZCkzZZksp9O3245Zkvalk02bjt9QpIkSb1nKJYkSVLvGYolSZLUe4ZiSZIk9Z6hWJIkSb1nKJYkSVLvGYolSZLUe4ZiSZIk9Z6hWJIkSb1nKJYkSVLvGYolSZLUe4ZiSZIk9Z6hWJIkSb03d7Y7IEmTWbz8S0Pd3+1nHjPU/UnqH8e10eWVYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm95y3ZpG3cMG/v4619JEnbK68US5IkqfcMxZIkSeo9Q7EkSZJ6z1AsSSMsyc5Jvp7km0luTPKOVr5XkiuTrE7y2SQ7tvKd2vPVrX7xwLbe2spvSXLEQPmRrWx1kuXDPkZJGgWGYkkabT8GDq2q5wH7AUcmORh4D3BWVe0N3A+c3NqfDNzfys9q7UiyL3A88GzgSOBDSeYkmQN8EDgK2Bc4obWVpF4xFEvSCKvO99rTHdqjgEOBC1v5ucCxbXlpe06rPyxJWvn5VfXjqvoOsBo4sD1WV9VtVfUT4PzWVpJ6xVAsSSOuXdG9FrgHuBT4NvBAVW1oTdYCC9ryAmANQKt/ENhtsHzcOpOVj+/DKUlWJVm1fv366To0SRoZhmJJGnFV9UhV7QcspLuy+6xZ6MPZVbWkqpbMnz9/2LuXpBlnKJakbURVPQBcDjwfmJdk7AeYFgLr2vI6YBFAq38KcO9g+bh1JiuXpF4xFEvSCEsyP8m8tvx44EXAzXTh+LjWbBlwUVte2Z7T6r9SVdXKj293p9gL2Af4OnAVsE+7m8WOdF/GWznzRyZJo8WfeZak0bYncG67S8TjgAuq6otJbgLOT3IGcA2worVfAXwiyWrgPrqQS1XdmOQC4CZgA3BqVT0CkOQ04BJgDnBOVd04vMOTpNFgKJakEVZV1wH7T1B+G9384vHlPwJeOsm23g28e4Lyi4GLt7qzkrQNc/qEJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN6bUihO8l+S3JjkhiSfSbJzkr2SXJlkdZLPJtmxtd2pPV/d6hfP5AFIkiRJW2uToTjJAuD1wJKqeg4wBzgeeA9wVlXtDdwPnNxWORm4v5Wf1dpJkiRJI2uq0yfmAo9PMhd4AnAncChwYas/Fzi2LS9tz2n1hyXJ9HRXkiRJmn6bDMVVtQ54L/AvdGH4QeBq4IGq2tCarQUWtOUFwJq27obWfrfx201ySpJVSVatX79+a49DkiRJ2mJTmT6xK93V372ApwFPBI7c2h1X1dlVtaSqlsyfP39rNydJkiRtsalMn/iPwHeqan1V/RvweeAFwLw2nQJgIbCuLa8DFgG0+qcA905rryVJkqRpNJVQ/C/AwUme0OYGHwbcBFwOHNfaLAMuassr23Na/Veqqqavy5IkSdL0msqc4ivpvjD3DeD6ts7ZwFuANyVZTTdneEVbZQWwWyt/E7B8BvotSZIkTZu5m24CVXU6cPq44tuAAydo+yPgpVvfNUmSJGk4/EU7SZIk9Z6hWJIkSb1nKJYkSVLvGYolSZLUe4ZiSZIk9Z6hWJJGWJJFSS5PclOSG5O8oZX/WZJ1Sa5tj6MH1nlrktVJbklyxED5ka1sdZLlA+V7JbmylX82yY7DPUpJmn2GYkkabRuAN1fVvsDBwKlJ9m11Z1XVfu1xMUCrOx54NnAk8KEkc5LMAT4IHAXsC5wwsJ33tG3tDdwPnDysg5OkUWEolqQRVlV3VtU32vLDwM3Ago2sshQ4v6p+XFXfAVbT3VP+QGB1Vd1WVT8BzgeWtl8qPZTuR5oAzgWOnZmjkaTRZSiWpG1EksXA/sCVrei0JNclOSfJrq1sAbBmYLW1rWyy8t2AB6pqw7hySeoVQ7EkbQOS7AJ8DnhjVT0EfBh4BrAfcCfwlzO8/1OSrEqyav369TO5K0maFYZiSRpxSXagC8SfqqrPA1TV3VX1SFX9FPgo3fQIgHXAooHVF7ayycrvBeYlmTuu/DGq6uyqWlJVS+bPnz99BydJI8JQLEkjrM35XQHcXFXvGyjfc6DZbwM3tOWVwPFJdkqyF7AP8HXgKmCfdqeJHem+jLeyqgq4HDiurb8MuGgmj0mSRtHcTTeRJM2iFwCvAK5Pcm0rexvd3SP2Awq4HXgNQFXdmOQC4Ca6O1ecWlWPACQ5DbgEmAOcU1U3tu29BTg/yRnANXQhXJJ6xVAsSSOsqq4AMkHVxRtZ593Auycov3ii9arqNh6dfiFJveT0CUmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPXe3NnugCRJ0pjFy7801P3dfuYxQ92fRpdXiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT13tzZ7oAkSZK2fYuXf2mo+7v9zGOmdXteKZYkSVLvGYolSZLUe4ZiSZIk9Z6hWJIkSb1nKJakEZZkUZLLk9yU5MYkb2jlT01yaZJb25+7tvIk+UCS1UmuS3LAwLaWtfa3Jlk2UP6rSa5v63wgSYZ/pJI0u6YUipPMS3Jhkn9OcnOS52/JgCxJ2mwbgDdX1b7AwcCpSfYFlgOXVdU+wGXtOcBRwD7tcQrwYehCNHA6cBBwIHD62Ljd2rx6YL0jh3BckjRSpnql+L8Df1tVzwKeB9zMZg7IkqTNV1V3VtU32vLDdOPvAmApcG5rdi5wbFteCpxXna8B85LsCRwBXFpV91XV/cClwJGt7slV9bWqKuC8gW1JUm9sMhQneQrwG8AKgKr6SVU9wOYPyJKkrZBkMbA/cCWwR1Xd2aruAvZoywuANQOrrW1lGytfO0H5+H2fkmRVklXr16/f6mORpFEzlSvFewHrgf8vyTVJPpbkiWz+gCxJ2kJJdgE+B7yxqh4arGtXeGsm919VZ1fVkqpaMn/+/JnclSTNiqmE4rnAAcCHq2p/4Ps8OlUC2LIB2asOkjQ1SXagC8SfqqrPt+K7xz6Fa3/e08rXAYsGVl/YyjZWvnCCcknqlamE4rXA2qq6sj2/kC4kb+6A/BhedZCkTWt3glgB3FxV7xuoWgmM3UFiGXDRQPmJ7UvPBwMPtk/1LgEOT7Jr+4Ld4cAlre6hJAe3fZ04sC1J6o1NhuKqugtYk+SZregw4CY2f0CWJG2+FwCvAA5Ncm17HA2cCbwoya3Af2zPAS4GbgNWAx8FXgdQVfcB7wKuao93tjJam4+1db4NfHkYByZJo2TuFNv9Z+BTSXakG2xfSReoL0hyMnAH8LLW9mLgaLrB9QetrSRpC1TVFcBk9w0+bIL2BZw6ybbOAc6ZoHwV8Jyt6KYkbfOmFIqr6lpgyQRVmzUgS5IkSaPIX7STJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSJEm9ZyiWJElS7xmKJUmS1HuGYkmSJPWeoViSRliSc5Lck+SGgbI/S7IuybXtcfRA3VuTrE5yS5IjBsqPbGWrkywfKN8ryZWt/LNJdhze0UnS6DAUS9Jo+zhw5ATlZ1XVfu1xMUCSfYHjgWe3dT6UZE6SOcAHgaOAfYETWluA97Rt7Q3cD5w8o0cjSSPKUCxJI6yq/hG4b4rNlwLnV9WPq+o7wGrgwPZYXVW3VdVPgPOBpUkCHApc2NY/Fzh2Wg9AkrYRhmJJ2jadluS6Nr1i11a2AFgz0GZtK5usfDfggaraMK5cknrHUCxJ254PA88A9gPuBP5ypneY5JQkq5KsWr9+/UzvTpKGbu5sd0CaaYuXf2mo+7v9zGOGuj/1T1XdPbac5KPAF9vTdcCigaYLWxmTlN8LzEsyt10tHmw/fp9nA2cDLFmypKbhMCRppHilWJK2MUn2HHj628DYnSlWAscn2SnJXsA+wNeBq4B92p0mdqT7Mt7KqirgcuC4tv4y4KJhHIMkjRqvFEvSCEvyGeAQYPcka4HTgUOS7AcUcDvwGoCqujHJBcBNwAbg1Kp6pG3nNOASYA5wTlXd2HbxFuD8JGcA1wArhnRokjRSDMWSNMKq6oQJiicNrlX1buDdE5RfDFw8QfltdHenkKRec/qEJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSes9QLEmSpN4zFEuSJKn3DMWSJEnqPUOxJEmSem/KoTjJnCTXJPlie75XkiuTrE7y2SQ7tvKd2vPVrX7xzHRdkiRJmh6bc6X4DcDNA8/fA5xVVXsD9wMnt/KTgftb+VmtnSRJkjSyphSKkywEjgE+1p4HOBS4sDU5Fzi2LS9tz2n1h7X2kiRJ0kia6pXi9wN/DPy0Pd8NeKCqNrTna4EFbXkBsAag1T/Y2j9GklOSrEqyav369VvYfUmSJGnrbTIUJ3kxcE9VXT2dO66qs6tqSVUtmT9//nRuWpIkSdosc6fQ5gXAS5IcDewMPBn478C8JHPb1eCFwLrWfh2wCFibZC7wFODeae+5JEmSNE02eaW4qt5aVQurajFwPPCVqno5cDlwXGu2DLioLa9sz2n1X6mqmtZeS5IkSdNoa+5T/BbgTUlW080ZXtHKVwC7tfI3Acu3rouSJEnSzJrK9ImfqaqvAl9ty7cBB07Q5kfAS6ehb5IkSdJQ+It2kiRJ6j1DsSRJknrPUCxJkqTeMxRLkiSp9wzFkiRJ6j1DsSRJknrPUCxJkqTeMxRLkiSp9wzFkiRJ6j1DsSRJknrPUCxJkqTeMxRLkiSp9wzFkiRJ6j1DsSRJknrPUCxJkqTeMxRLkiSp9wzFkiRJ6j1DsSRJknrPUCxJkqTeMxRLkiSp9wzFkiRJ6j1DsSRJknrPUCxJkqTeMxRL0ghLck6Se5LcMFD21CSXJrm1/blrK0+SDyRZneS6JAcMrLOstb81ybKB8l9Ncn1b5wNJMtwjlKTRYCiWpNH2ceDIcWXLgcuqah/gsvYc4Chgn/Y4BfgwdCEaOB04CDgQOH0sSLc2rx5Yb/y+JKkXDMWSNMKq6h+B+8YVLwXObcvnAscOlJ9Xna8B85LsCRwBXFpV91XV/cClwJGt7slV9bWqKuC8gW1JUq8YiiVp27NHVd3Zlu8C9mjLC4A1A+3WtrKNla+doPznJDklyaokq9avX7/1RyBJI2bubHdAkrTlqqqS1BD2czZwNsCSJUtmfH/bmsXLvzTU/d1+5jFD3Z/UB14plqRtz91t6gPtz3ta+Tpg0UC7ha1sY+ULJyiXpN4xFEvStmclMHYHiWXARQPlJ7a7UBwMPNimWVwCHJ5k1/YFu8OBS1rdQ0kObnedOHFgW5LUK06fkKQRluQzwCHA7knW0t1F4kzggiQnA3cAL2vNLwaOBlYDPwBeCVBV9yV5F3BVa/fOqhr78t7r6O5w8Xjgy+0hSb1jKJakEVZVJ0xSddgEbQs4dZLtnAOcM0H5KuA5W9NHSdoeOH1CkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT13iZDcZJFSS5PclOSG5O8oZU/NcmlSW5tf+7aypPkA0lWJ7kuyQEzfRCSJEnS1pjKleINwJuratCV7qwAAAqRSURBVF/gYODUJPsCy4HLqmof4LL2HOAoYJ/2OAX48LT3WpIkSZpGmwzFVXVnVX2jLT8M3AwsAJYC57Zm5wLHtuWlwHnV+RowL8me095zSZIkaZps1pziJIuB/YErgT2q6s5WdRewR1teAKwZWG1tKxu/rVOSrEqyav369ZvZbUmSJGn6TDkUJ9kF+Bzwxqp6aLCuqgqozdlxVZ1dVUuqasn8+fM3Z1VJkiRpWk0pFCfZgS4Qf6qqPt+K7x6bFtH+vKeVrwMWDay+sJVJkiRJI2kqd58IsAK4uareN1C1EljWlpcBFw2Un9juQnEw8ODANAtJkiRp5MydQpsXAK8Ark9ybSt7G3AmcEGSk4E7gJe1uouBo4HVwA+AV05rjyVJkqRptslQXFVXAJmk+rAJ2hdw6lb2S5IkSRoaf9FOkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJ2kYluT3J9UmuTbKqlT01yaVJbm1/7trKk+QDSVYnuS7JAQPbWdba35pk2WT7k6Tt2VR+0U6SNLp+s6q+O/B8OXBZVZ2ZZHl7/hbgKGCf9jgI+DBwUJKnAqcDS4ACrk6ysqrun+6OLl7+pene5EbdfuYxQ92fpG2bV4olafuyFDi3LZ8LHDtQfl51vgbMS7IncARwaVXd14LwpcCRw+60JM02Q7EkbbsK+LskVyc5pZXtUVV3tuW7gD3a8gJgzcC6a1vZZOWPkeSUJKuSrFq/fv10HoMkjQSnT4woP2aUNAUvrKp1SX4BuDTJPw9WVlUlqenYUVWdDZwNsGTJkmnZpiSNEq8US9I2qqrWtT/vAb4AHAjc3aZF0P68pzVfBywaWH1hK5usXJJ6xVAsSdugJE9M8qSxZeBw4AZgJTB2B4llwEVteSVwYrsLxcHAg22axSXA4Ul2bXeqOLyVSVKvOH1CkrZNewBfSALdWP7pqvrbJFcBFyQ5GbgDeFlrfzFwNLAa+AHwSoCqui/Ju4CrWrt3VtV9wzsMSRoNhmJJ2gZV1W3A8yYovxc4bILyAk6dZFvnAOdMdx8laVvi9AlJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT1nqFYkiRJvWcoliRJUu8ZiiVJktR7hmJJkiT13tzZ7sDWWLz8S0Pd3+1nHjPU/UmSJGk4vFIsSZKk3jMUS5IkqfcMxZIkSeo9Q7EkSZJ6z1AsSZKk3jMUS5IkqfcMxZIkSeo9Q7EkSZJ6z1AsSZKk3jMUS5IkqfcMxZIkSeo9Q7EkSZJ6z1AsSZKk3jMUS5IkqfcMxZIkSeo9Q7EkSZJ6z1AsSZKk3jMUS5IkqfdmJBQnOTLJLUlWJ1k+E/uQJE0fx21JfTftoTjJHOCDwFHAvsAJSfad7v1IkqaH47YkzcyV4gOB1VV1W1X9BDgfWDoD+5EkTQ/HbUm9NxOheAGwZuD52lYmSRpNjtuSei9VNb0bTI4DjqyqV7XnrwAOqqrTxrU7BTilPX0mcMsW7G534Ltb0d3pMir9APsykVHpB4xOX0alH7Dt9+XpVTV/JjozLFMZt7ezMRtGpy+j0g8Ynb6MSj/AvkxkVPoBW96XCcftuVvfn5+zDlg08HxhK3uMqjobOHtrdpRkVVUt2ZptTIdR6QfYl1HuB4xOX0alH2BfRsQmx+3tacyG0enLqPQDRqcvo9IPsC+j3A+Y/r7MxPSJq4B9kuyVZEfgeGDlDOxHkjQ9HLcl9d60Xymuqg1JTgMuAeYA51TVjdO9H0nS9HDclqSZmT5BVV0MXDwT2x5nqz7Km0aj0g+wLxMZlX7A6PRlVPoB9mUkDGncHqXzOyp9GZV+wOj0ZVT6AfZlIqPSD5jmvkz7F+0kSZKkbY0/8yxJkqTeG/lQnOScJPckuWGS+iT5QPtp0uuSHDCLfTkkyYNJrm2PP52hfixKcnmSm5LcmOQNE7SZ8fMyxX4M65zsnOTrSb7Z+vKOCdrslOSz7ZxcmWTxLPblpCTrB87Lq2aiL21fc5Jck+SLE9QN5ZxMsS9DOSdJbk9yfdvHqgnqhzambI8csyfcz0iM2ZvRlxk/L47ZG+2PY/bP72s443ZVjfQD+A3gAOCGSeqPBr4MBDgYuHIW+3II8MUhnJM9gQPa8pOAbwH7Dvu8TLEfwzonAXZpyzsAVwIHj2vzOuAjbfl44LOz2JeTgL+e6fPS9vUm4NMT/T0M65xMsS9DOSfA7cDuG6kf2piyPT4csyfcz0iM2ZvRlxk/L47ZG+2PY/bP72so4/bIXymuqn8E7ttIk6XAedX5GjAvyZ6z1JehqKo7q+obbflh4GZ+/tenZvy8TLEfQ9GO83vt6Q7tMX7C/FLg3LZ8IXBYksxSX4YiyULgGOBjkzQZyjmZYl9GxdDGlO2RY/aE/RiJMXsz+jLjHLMn5pi9xabl/8/Ih+IpGLWfJ31++wjmy0mePdM7ax+d7E/3znbQUM/LRvoBQzon7WOea4F7gEuratJzUlUbgAeB3WapLwC/2z7muTDJognqp8P7gT8GfjpJ/dDOyRT6AsM5JwX8XZKr0/1K23ijNqZsb0bt/PZyzN5EX2AI58Uxe0KO2RMbyri9PYTiUfINup8OfB7wV8DfzOTOkuwCfA54Y1U9NJP72op+DO2cVNUjVbUf3a9xHZjkOTO1r2noy/8EFlfVc4FLefSd/7RJ8mLgnqq6erq3PUN9mfFz0rywqg4AjgJOTfIbM7Qfjb5ejtlT6MtQzotj9mM5Zm/UUMbt7SEUT+lnpYehqh4a+wimunt+7pBk95nYV5Id6Aa0T1XV5ydoMpTzsql+DPOcDOzzAeBy4MhxVT87J0nmAk8B7p2NvlTVvVX14/b0Y8CvzsDuXwC8JMntwPnAoUk+Oa7NsM7JJvsypHNCVa1rf94DfAE4cFyTkRlTtlMjc377OGZPpS/DHrcds3/GMXsSwxq3t4dQvBI4sX3z8GDgwaq6czY6kuQXx+b2JDmQ7vxO+z/Wto8VwM1V9b5Jms34eZlKP4Z4TuYnmdeWHw+8CPjncc1WAsva8nHAV6pq2ueNTaUv4+Y6vYRuXt+0qqq3VtXCqlpM94WMr1TVH4xrNpRzMpW+DOOcJHlikieNLQOHA+PvTDAyY8p2amTOb9/G7Kn2ZRjnxTH75zlmT2yY4/aM/KLddEryGbpvwu6eZC1wOt0keKrqI3S/wHQ0sBr4AfDKWezLccAfJtkA/BA4fib+sdK9g3sFcH2bAwXwNuCXBvoyjPMylX4M65zsCZybZA7dAH5BVX0xyTuBVVW1ku6F4BNJVtN9+eb4GejHVPvy+iQvATa0vpw0Q335ObN0TqbSl2Gckz2AL7TX+7nAp6vqb5O8FoY/pmyPHLMnNCpj9lT7Mozz4pg9RT0fs2GI47a/aCdJkqTe2x6mT0iSJElbxVAsSZKk3jMUS5IkqfcMxZIkSeo9Q7EkSZJ6z1AsSZKk3jMUS5IkqfcMxZIkSeq9/wvmaoj05aECtwAAAABJRU5ErkJggg==%0A">
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="recohut-admin/reco-nb-stage"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/rl/movie/tensorflow%201x/2021/07/22/listwise-movie-recommendations-using-rl-methods.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>RecoHut&#39;s official notebooks portal, contains interactive jupyter notebooks on recommender systems.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/recohut" title="recohut"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
